<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Low-Rank Approximation · RLinearAlgebra</title><meta name="title" content="Low-Rank Approximation · RLinearAlgebra"/><meta property="og:title" content="Low-Rank Approximation · RLinearAlgebra"/><meta property="twitter:title" content="Low-Rank Approximation · RLinearAlgebra"/><meta name="description" content="Documentation for RLinearAlgebra."/><meta property="og:description" content="Documentation for RLinearAlgebra."/><meta property="twitter:description" content="Documentation for RLinearAlgebra."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">RLinearAlgebra</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox" checked/><label class="tocitem" for="menuitem-2"><span class="docs-label">Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../introduction/">Introduction</a></li><li><a class="tocitem" href="../compression/">Compression</a></li><li class="is-active"><a class="tocitem" href>Low-Rank Approximation</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#The-Randomized-Rangefinder"><span>The Randomized Rangefinder</span></a></li><li><a class="tocitem" href="#A-RangeFinder-Example"><span>A RangeFinder Example</span></a></li><li class="toplevel"><a class="tocitem" href="#The-RandSVD"><span>The RandSVD</span></a></li><li><a class="tocitem" href="#A-RandSVD-example"><span>A RandSVD example</span></a></li></ul></li><li><a class="tocitem" href="../linear_systems/">Linear Systems</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/tutorials_overview/">Overview of Tutorials</a></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Compressors</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/compressors/compressor_example/">Multiplying by a Compressor</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Consistent Linear System</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/consistent_system/consistent_system/">Solving a Consistent Linear System</a></li><li><a class="tocitem" href="../../tutorials/consistent_system/configuring_kaczmarz/">Configuring a Basic Logger for the Generalized Kaczmarz Solver</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Least Squares</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/least_squares/least_squares/">Solving a Least Squares Problem</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">API Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Compressors</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../api/compressors/">Compressors API</a></li><li><a class="tocitem" href="../../api/distributions/">Distributions API</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Solvers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../api/solvers/">Solvers API</a></li><li><a class="tocitem" href="../../api/sub_solvers/">SubSolvers API</a></li><li><a class="tocitem" href="../../api/solver_errors/">SolverErrors API</a></li><li><a class="tocitem" href="../../api/loggers/">Loggers API</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Approximators</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../api/approximators/">Approximators API</a></li><li><a class="tocitem" href="../../api/selectors/">Selectors API</a></li><li><a class="tocitem" href="../../api/approximator_errors/">ApproximatorErrors API</a></li></ul></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Low-Rank Approximation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Low-Rank Approximation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/numlinalg/RLinearAlgebra.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/numlinalg/RLinearAlgebra.jl/blob/main/docs/src/manual/low_rank_approximators.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Low-Rank-Approximations-of-Matrices"><a class="docs-heading-anchor" href="#Low-Rank-Approximations-of-Matrices">Low-Rank Approximations of Matrices</a><a id="Low-Rank-Approximations-of-Matrices-1"></a><a class="docs-heading-anchor-permalink" href="#Low-Rank-Approximations-of-Matrices" title="Permalink"></a></h1><p>Often large matrices contain a lot of redundant information. This means that it is often  possible to form representations of large matrices with far fewer vectors than what the  original matrix contains. Representing a matrix with a small number of vectors  is known as low-rank approximation. Generally, low-rank approximations of a matrix <span>$A \in \mathbb{R}^{m \times n}$</span> take two forms either a two matrix form where <span>$A \approx MN,$</span>  where <span>$M \in \mathbb{R}^{m \times r}$</span> and <span>$N \in \mathbb{R}^{r \times n}$</span>, or the three matrix form where  <span>$A \approx MBN$</span> and <span>$M \in \mathbb{R}^{m \times r}$</span>, <span>$N \in \mathbb{R}^{s \times n}$</span>, and  <span>$B \in \mathbb{R}^{r \times s}$</span>. </p><p>Once one of the above representations has been obtained they can then be used to speed up: matrix multiplication, clustering, or approximate eigenvalue decompositions  [<a href="../../references/#halko2011finding">1</a>–<a href="../../references/#park2025curing">4</a>].</p><p>Low rank approximations can take two different forms one being the orthogonal projection  form where coordinates are projected perpendicularly to onto a plane and the second being the oblique forms where points are projected along another plane (see the below figure  for a visualization).</p><img src="../images/projection.png" width =400 height = 300/> <p>We also can consider low-rank approximations for symmetric matrices and general matrices. For symmetric and general matrices, the RandomizedSVD can be used as the orthogonal  projection method [<a href="../../references/#halko2011finding">1</a>].   </p><p>As far as oblique methods go, the difference between symmetric and asymmetric decompositions becomes more complicated. For symmetric matrices, the go to approximation is the Nystrom approximation. For the non-symmetric matrices, we can have a generalization of Nystrom  known as Generalized Nystrom or we can interpolative approaches, which select subsets of  the rows and/or columns to a matrix. If it these interpolative decompositions are performed  to select only columns or only rows then they are known as one sided IDs, if they are used  to select both columns and rows then they are known as a CUR decomposition. Below, we  present a summary of the decompositions in a table. </p><table><tr><th style="text-align: left">Approximation Name</th><th style="text-align: left">General Matrices</th><th style="text-align: left">Interpolative</th><th style="text-align: left">Type</th><th style="text-align: left">Form of Approximation</th></tr><tr><td style="text-align: left">RandRangeFinder</td><td style="text-align: left">Yes</td><td style="text-align: left">No</td><td style="text-align: left">Orthogonal</td><td style="text-align: left"><span>$A \approx QQ^\top A$</span></td></tr><tr><td style="text-align: left">RandSVD</td><td style="text-align: left">Yes</td><td style="text-align: left">No</td><td style="text-align: left">Orthogonal</td><td style="text-align: left"><span>$A \approx U \Sigma V^\top$</span></td></tr><tr><td style="text-align: left">Nystrom</td><td style="text-align: left">Symmetric</td><td style="text-align: left">Can be</td><td style="text-align: left">Oblique</td><td style="text-align: left"><span>$(AS)((SA)^\top AS)^\dagger(AS)^\top$</span></td></tr><tr><td style="text-align: left">Generalizedd Nystrom</td><td style="text-align: left">Yes</td><td style="text-align: left">Can be</td><td style="text-align: left">Oblique</td><td style="text-align: left"><span>$(AS_1)(S_2A AS_1)^\dagger S_2 A$</span></td></tr><tr><td style="text-align: left">CUR</td><td style="text-align: left">Yes</td><td style="text-align: left">Yes</td><td style="text-align: left">Oblique</td><td style="text-align: left"><span>$(A[:,J])U(A[I,:])$</span></td></tr><tr><td style="text-align: left">One-Sided-ID</td><td style="text-align: left">Yes</td><td style="text-align: left">Yes</td><td style="text-align: left">Oblique</td><td style="text-align: left"><span>$A[:,J]U_c$</span> or <span>$U_r A[I,:]$</span></td></tr></table><p>In RLinearAlgebra,  once you have obtained a low-rank approximation <code>Recipe</code> you can then use it to perform  multiplications in all cases or in some specific areas use it to precondition a linear  system through the <code>ldiv!</code> function. Below we have the table of approximation recipes  and indicate how they can be used.</p><table><tr><th style="text-align: left">Approximation Name</th><th style="text-align: left"><code>mul!</code></th><th style="text-align: left"><code>ldiv!</code></th></tr><tr><td style="text-align: left">RandRangeFinderRecipe</td><td style="text-align: left">Yes</td><td style="text-align: left">No</td></tr><tr><td style="text-align: left">RandSVDRecipe</td><td style="text-align: left">Yes</td><td style="text-align: left">No</td></tr><tr><td style="text-align: left">NystromRecipe</td><td style="text-align: left">Yes</td><td style="text-align: left">No</td></tr><tr><td style="text-align: left">CURRecipe</td><td style="text-align: left">Yes</td><td style="text-align: left">No</td></tr><tr><td style="text-align: left">IDRecipe(One-Sided-ID)</td><td style="text-align: left">Yes</td><td style="text-align: left">No</td></tr></table><h1 id="The-Randomized-Rangefinder"><a class="docs-heading-anchor" href="#The-Randomized-Rangefinder">The Randomized Rangefinder</a><a id="The-Randomized-Rangefinder-1"></a><a class="docs-heading-anchor-permalink" href="#The-Randomized-Rangefinder" title="Permalink"></a></h1><p>The idea behind the randomized range finder is to find an orthogonal matrix <span>$Q$</span> such that <span>$A \approx QQ^\top A$</span>. In their seminal work [<a href="../../references/#halko2011finding">1</a>] showed that  forming <span>$Q$</span> was as simple as compressing <span>$A$</span> from the right  and storing the Q from the resulting QR factorization. Despite the simplicity of this procedure they were able to show  if the compression dimension, <span>$k&gt;2$</span>, then <span>$\|A - QQ^\top A\|_F \leq \sqrt{k+1} (\sum_{i=k+1}^{\min{(m,n)}}\sigma_{i})^{1/2}$</span>,      where <span>$\sigma_{k+1}$</span> is the <span>$k+1^\text{th}$</span> singular value of A (see Theorem 10.5  of [<a href="../../references/#halko2011finding">1</a>]). This is very close to the error from the truncated SVD, which  is known to be the lowest achievable error. </p><p>For many matrices that singular values that decay quickly, this bound can be far more  conservative than the observed performance. However, for some matrices whose singular values  decay slowly this bound is fairly tight. Luckily, using power iterations we can  still improve the quality of the approximation. Power Iterations basically involve multiplying the matrix with itself, which results in raising each singular value to a  higher power. This powering of the singular values increases the gap between the singular  values making them easier to accurately capture. In <code>RLinearAlgebra</code>, you can control the number of power iterations using the <code>power_its</code> keyword in the constructor. </p><p>One issue with power iterations is that they can sometimes be  unstable. We can also improve the stability of these iterations by orthogonalizing between power iterations. Meaning that instead of computing <span>$A A^\top A$</span> as is done in the power  iterations we compute <span>$A^\top A$</span> and take a QR factorization of this matrix to obtain a  <span>$Q$</span> then compute <span>$A Q$</span>. In RLinearAlgebra you can control whether or not the orthogonalization is performed using the <code>orthogonalize</code> keyword argument in the  constructor. </p><div class="admonition is-info" id="Info-9ce07218bfbc1a55"><header class="admonition-header">Info<a class="admonition-anchor" href="#Info-9ce07218bfbc1a55" title="Permalink"></a></header><div class="admonition-body"><p>If the cardinality of the compressor in the <code>RangeFinder</code> is not <code>Right()</code> a warning  will be returned and the approximation may be incorrect.  </p></div></div><h2 id="A-RangeFinder-Example"><a class="docs-heading-anchor" href="#A-RangeFinder-Example">A RangeFinder Example</a><a id="A-RangeFinder-Example-1"></a><a class="docs-heading-anchor-permalink" href="#A-RangeFinder-Example" title="Permalink"></a></h2><p>Lets say that we wish to obtain a rank-5 RandomizedSVD to matrix with 1000 rows and columns. In RLinearAlgebra.jl we can do this by first generating the <code>RandomizedSVD</code> <code>Approximator</code>. This will require us to specify a <code>Compressor</code> with the desired rank of approximation as the <code>compression_dim</code> and the <code>cardinality=Right()</code>, the number of power iterations we want  to be performed, and whether we want to orthogonalize the power iterations. </p><p>To begin, we consider forming an approximation to a rank 5 matrix with 1000 rows and  columns. Then will define a <code>RangeFinder</code> structure with a <code>FJLT</code> compressor with a   <code>compression_dim = 5</code> and a  <code>cardinality = Right()</code>. After defining this structure we will then use <code>rapproximate</code> to  generate a <code>RangeFinderRecipe</code>, which we will then compute the error relying on the ability  to multiply <code>RangeFinderRecipe</code>s.</p><pre><code class="language-julia hljs">using RLinearAlgebra, LinearAlgebra

# Generate the matrix we wish to approximate
A = randn(1000, 5) * randn(5, 1000);

# Form the RangeFinder Structure
approx = RangeFinder(
    compressor = FJLT(compression_dim = 5, cardinality = Right())
)

# Approximate A
range_A = rapproximate(approx, A)

# Check the error of the approximation
norm(A - range_A * (range_A&#39; * A))</code></pre><p>To see the benefits of power iterations we consider the same example but now with  <code>compression_dim = 3</code>, then we consider the truncated SVD error,  the error of an approximation with no power iterations,  the error of an approximation with 10 power iterations but no orthogonalization, and the error of an approximation with 10 power iterations and  orthogonalization.</p><pre><code class="language-julia hljs"># Get error of truncated svd by computing the sqrt of the sum^2 of singular values 4:1000
printstyled(&quot;Error of rank 3 truncated SVD:&quot;,
    sqrt(sum(svd(A).S[4:end].^2)),
    &quot;\n&quot;
)

# Try approximating with a compression dimension of 3 and no power its/orthogonalization 
# Form the RangeFinder Structure
approx = RangeFinder(
    compressor = FJLT(compression_dim = 3, cardinality = Right())
);

range_A = rapproximate(approx, A);

printstyled(&quot;Error of rank 3 approximation:&quot;,
    norm(A - range_A * (range_A&#39; * A)),
    &quot;\n&quot;
)

# Now consider adding power iterations 
approx_pi = RangeFinder(
    compressor = FJLT(compression_dim = 3, cardinality = Right()),
    power_its = 10
);

range_A_pi = rapproximate(approx_pi, A);


printstyled(&quot;Error with 10 Power its and Orthogonalization:&quot;,
    norm(A - range_A_pi * (range_A_pi&#39; * A)),
    &quot;\n&quot;
)

# Now consider power its with orthogonalization
approx_pi_o = RangeFinder(
    compressor = FJLT(compression_dim = 3, cardinality = Right()),
    power_its = 10,
    orthogonalize = true
);

range_A_pi_o = rapproximate(approx_pi_o, A);

printstyled(&quot;Error with 10 Power its and Orthogonalization:&quot;,
    norm(A - range_A_pi_o * (range_A_pi_o&#39; * A)),
    &quot;\n&quot;
)</code></pre><h1 id="The-RandSVD"><a class="docs-heading-anchor" href="#The-RandSVD">The RandSVD</a><a id="The-RandSVD-1"></a><a class="docs-heading-anchor-permalink" href="#The-RandSVD" title="Permalink"></a></h1><p>The RandomizedSVD is a form of low-rank approximation that returns the approximate  singular values and vectors to the truncated SVD. Algorithmically, it is implemented as three additional steps to the Randomized Rangefinder in [<a href="../../references/#halko2011finding">1</a>].  Specifically these steps are:</p><ol><li>Take the <span>$Q$</span> matrix from the Randomized Rangefinder and compute <span>$Q^\top A$</span>.  </li><li>Compute the <span>$W,S,V = \text{svd}(Q^\top A)$</span>.</li><li>Obtain the left singular vectors from <span>$U = Q^\top W$</span>.</li></ol><p>Since, the RandomizedSVD is simply an extension of the Randomized RangeFinder, the effects of all modifications, such as power iterations and orthogonalization still apply.  The  difference between the two procedures is found in the Recipes. Where for the <code>RandSVDRecipe</code> you find a approximate truncated SVD where the singular values can be accessed by  calling <code>recipe.S</code>, the left singular vectors can be accessed by calling <code>recipe.U</code>, and the right singular vectors can be accessed by calling <code>recipe.V</code>. Additionally,  when you multiply with the RandomizedSVD it is as if you are multiplying with the  truncated SVD, meaning for a vector <span>$x$</span> the operation <span>$USV^\top x$</span> is performed. This  type of multiplication can be substantially faster than multiplications with the original  matrix.</p><div class="admonition is-info" id="Info-cb17c0e28bf513df"><header class="admonition-header">Info<a class="admonition-anchor" href="#Info-cb17c0e28bf513df" title="Permalink"></a></header><div class="admonition-body"><p>As for the RandomizedSVD if the cardinality of the compressor is not <code>Right()</code> a warning  will be returned and the approximation may be incorrect.</p></div></div><h2 id="A-RandSVD-example"><a class="docs-heading-anchor" href="#A-RandSVD-example">A RandSVD example</a><a id="A-RandSVD-example-1"></a><a class="docs-heading-anchor-permalink" href="#A-RandSVD-example" title="Permalink"></a></h2><p>We now demonstrate how to use the RandSVD, by first generating the technique structure  with a <code>FJLT</code> compressor with <code>compression_dim = 5</code> and <code>cardinality = Right()</code>. Then we  will run <code>rapproximate</code> and compare the singular values of the returned recipe to the  5 singular values of the truncated SVD. We will then end the experiment by comparing  the difference between multiplying a our <code>RandSVDRecipe</code> to vector and multiplying the  original matrix.</p><pre><code class="language-julia hljs">using RLinearAlgebra, LinearAlgebra

# Generate the matrix we wish to approximate
A = randn(1000, 5) * randn(5, 1000);

# Form the RangeFinder Structure
approx = RandSVD(
    compressor = FJLT(compression_dim = 5, cardinality = Right())
)

# Approximate A
randsvd_A = rapproximate(approx, A)

# Compare singular vectors
svd(A).S[1:5]

randsvd_A.S

# Compare multiplications
x = rand(1000);

norm(A * x - randsvd_A * x)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../compression/">« Compression</a><a class="docs-footer-nextpage" href="../linear_systems/">Linear Systems »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 9 January 2026 15:39">Friday 9 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
