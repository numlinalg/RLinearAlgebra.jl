var documenterSearchIndex = {"docs":
[{"location":"references/","page":"References","title":"References","text":"N. Halko, P. G. Martinsson and J. A. Tropp. Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions. SIAM Review 53, 217–288 (2011).\n\n\n\nC. Eckart and G. Young. The Approximation of One Matrix by Another of Lower Rank. Psychometrika 1, 211–218 (1936).\n\n\n\nM. Udell and A. Townsend. Why Are Big Data Matrices Approximately Low Rank? SIAM Journal on Mathematics of Data Science 1, 144–160 (2019).\n\n\n\nS. Park and S.-M. Moon. CURing Large Models: Compression via CUR Decomposition (Jan 2025), arXiv:2501.04211 [cs].\n\n\n\nP.-G. Martinsson and J. Tropp. Randomized Numerical Linear Algebra: Foundations &amp; Algorithms (2020).\n\n\n\nV. Patel, M. Jahangoshahi and D. A. Maldonado. Randomized Block Adaptive Linear System Solvers. SIAM Journal on Matrix Analysis and Applications 44, 1349–1369 (2023).\n\n\n\nD. P. Woodruff. Sketching as a Tool for Numerical Linear Algebra. Foundations and Trends in Theoretical Computer Science 10, 1–157 (2014).\n\n\n\nN. Ailon and B. Chazelle. The Fast Johnson–Lindenstrauss Transform and Approximate Nearest Neighbors. SIAM Journal on Computing 39, 302–322 (2009).\n\n\n\nJ. A. Tropp. Improved Analysis of the Subsampled Randomized Hadamard Transform. Advances in Adaptive Data Analysis 03, 115–126 (2011).\n\n\n\nT. S. Motzkin and I. J. Schoenberg. The Relaxation Method for Linear Inequalities. Canadian Journal of Mathematics 6, 393–404 (1954).\n\n\n\nM. Pilanci and M. J. Wainwright. Iterative Hessian Sketch: Fast and Accurate Solution Approximation for Constrained Least-Squares (2014).\n\n\n\nT. Strohmer and R. Vershynin. A Randomized Kaczmarz Algorithm with Exponential Convergence. Journal of Fourier Analysis and Applications 15, 262–278 (2009).\n\n\n\nD. Needell and J. A. Tropp. Paved with Good Intentions: Analysis of a Randomized Block Kaczmarz Method. Linear Algebra and its Applications 441, 199–221 (2014).\n\n\n\nY. Shitov. Column Subset Selection Is NP-complete. Linear Algebra and its Applications 610, 52–58 (2021).\n\n\n\nA. Osinsky. Close to Optimal Column Approximation Using a Single SVD. Linear Algebra and its Applications 725, 359–377 (2025).\n\n\n\nM. W. Mahoney and P. Drineas. CUR Matrix Decompositions for Improved Data Analysis. Proceedings of the National Academy of Sciences 106, 697–702 (2009).\n\n\n\nY. Dong and P.-G. Martinsson. Simpler Is Better: A Comparative Study of Randomized Pivoting Algorithms for CUR and Interpolative Decompositions. Advances in Computational Mathematics 49, 66 (2023).\n\n\n\nT. Park and Y. Nakatsukasa. Accuracy and Stability of CUR Decompositions with Oversampling. SIAM Journal on Matrix Analysis and Applications 46, 780–810 (2025).\n\n\n\n","category":"section"},{"location":"tutorials/tutorials_overview/#Overview-of-Tutorials","page":"Overview of Tutorials","title":"Overview of Tutorials","text":"Below are examples of using different routines available in RLinearAlgebra.jl. \n\nMultiplying by a Compressor demonstrates how to compress a matrix by   multiplication with a compressor.\nSolving a Consistent Linear System demonstrates how to approximately find   x that solves Ax = b when b is in the column space of A using the default   solver.\nConfiguring a Basic Logger for the Generalized Kaczmarz Solver demonstrates    how to customize the BasicLogger argument for a Kaczmarz solver.\nSolving a Least Squares Problem demonstrates how to approximately solve    min_xAx - b_2^2.","category":"section"},{"location":"api/selectors/#Selectors","page":"Selectors API","title":"Selectors","text":"Pages = [\"selectors.md\"]","category":"section"},{"location":"api/selectors/#Abstract-Types","page":"Selectors API","title":"Abstract Types","text":"","category":"section"},{"location":"api/selectors/#Selector-Structures","page":"Selectors API","title":"Selector Structures","text":"","category":"section"},{"location":"api/selectors/#Exported-Functions","page":"Selectors API","title":"Exported Functions","text":"","category":"section"},{"location":"api/selectors/#Internal-Functions","page":"Selectors API","title":"Internal Functions","text":"","category":"section"},{"location":"api/selectors/#RLinearAlgebra.Selector","page":"Selectors API","title":"RLinearAlgebra.Selector","text":"Selector\n\nAn abstract type containing user controlled parameters for a technique that selects indices from a matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/selectors/#RLinearAlgebra.SelectorRecipe","page":"Selectors API","title":"RLinearAlgebra.SelectorRecipe","text":"SelectorRecipe\n\nAn abstract type containing user controlled parameters and preallocated memory for a technique that selects indices from a matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/selectors/#RLinearAlgebra.LUPP","page":"Selectors API","title":"RLinearAlgebra.LUPP","text":"LUPP <: Selector\n\nA Selector that implements LU with partial pivoting for selecting column indices from a  matrix.\n\nFields\n\ncompressor::Compressor, the compression technique that will be applied to the matrix,    before selecting indices.\n\nConstructor\n\nLUPP(;compressor = Identity())\n\nKeywords\n\ncompressor::Compressor, the compression technique that will be applied to the matrix,    before selecting indices. Defaults to the Identity compressor.\n\nReturns\n\nA LUPP object.\n\nnote: Implementation Note\nLU with partial pivoting is classically implemented to select rows of a matrix. Here we  apply LU with partial pivoting to the transpose of the inputted matrix to select  columns.\n\n\n\n\n\n","category":"type"},{"location":"api/selectors/#RLinearAlgebra.LUPPRecipe","page":"Selectors API","title":"RLinearAlgebra.LUPPRecipe","text":"LUPPRecipe <: SelectorRecipe\n\nA SelectorRecipe that contains all the necessary preallocations for selecting column  indices from a matrix using LU with partial pivoting.\n\nFields\n\ncompressor::CompressorRecipe, the compression technique that will applied to the matrix,    before selecting indices.\nSA::AbstractMatrix, a buffer matrix for storing the sketched matrix.\n\nnote: Implementation Note\nLU with partial pivoting is classically implemented to select rows of a matrix. Here we  apply LU with partial pivoting to the transpose of the inputted matrix to select  columns.\n\n\n\n\n\n","category":"type"},{"location":"api/selectors/#RLinearAlgebra.QRCP","page":"Selectors API","title":"RLinearAlgebra.QRCP","text":"QRCP <: Selector\n\nA Selector that implements QR with column norm pivoting for selecting column indices from   a matrix.\n\nFields\n\ncompressor::Compressor, the compression technique that will be applied to the matrix,    before selecting indices.\n\nConstructor\n\nQRCP(;compressor = Identity())\n\nKeywords\n\ncompressor::Compressor, the compression technique that will applied to the matrix,    before selecting indices. Defaults the Identity compressor.\n\nReturns\n\nA QRCP object.\n\n\n\n\n\n","category":"type"},{"location":"api/selectors/#RLinearAlgebra.QRCPRecipe","page":"Selectors API","title":"RLinearAlgebra.QRCPRecipe","text":"QRCPRecipe <: SelectorRecipe\n\nA SelectorRecipe that contains all the necessary preallocations for selecting column  indices from a matrix using QR with column norm pivoting.\n\nFields\n\ncompressor::Compressor, the compression technique that will be applied to the matrix,    before selecting indices.\nSA::AbstractMatrix, a buffer matrix for storing the compressed matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/selectors/#RLinearAlgebra.complete_selector","page":"Selectors API","title":"RLinearAlgebra.complete_selector","text":"complete_selector(selector::Selector, A::AbstractMatrix)\n\nA function that generates a SelectorRecipe given     arguments.\n\nArguments\n\nselector::Selector, a data structure containing the user-defined   parameters associated with a particular selection method.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nA SelectorRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/selectors/#RLinearAlgebra.update_selector!","page":"Selectors API","title":"RLinearAlgebra.update_selector!","text":"update_selector!(selector::SelectorRecipe)\n\nA function that updates the SelectorRecipe in place given the     arguments.\n\nArguments\n\nselector::SelectorRecipe, a fully initialized realization   for a selector method for a particular matrix.\n\nOutputs\n\nA SelectorRecipe object.\n\n\n\n\n\nupdate_selector!(selector::SelectorRecipe, A::AbstractMatrix)\n\nA function that updates the SelectorRecipe in place given the     arguments.\n\nArguments\n\nselector::SelectorRecipe, a fully initialized realization   for a selector method for a particular matrix.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nA SelectorRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/selectors/#RLinearAlgebra.select_indices!","page":"Selectors API","title":"RLinearAlgebra.select_indices!","text":"select_indices!(\n    idx::AbstractVector,\n    selector::SelectorRecipe, \n    A::AbstractMatrix,\n    n_idx::Int64, \n    start_idx::Int64\n)\n\nA function that selects indices from a matrix A using a specific     SelectorRecipe. It updates the vector idx in place with n_idx new indices starting     at index start_idx.\n\nArguments\n\nidx::vector, a vector where selected indices will be placed.\nselector::SelectorRecipe, a fully initialized realization   for a selector method for a particular matrix.\nA::AbstractMatrix, a target matrix for approximation. \nn_idx::Int64, the number of indices to be selected.\nstart_idx::Int64. the starting location in idx where the indices    will be placed.\n\nOutputs\n\nReturns nothing\n\n\n\n\n\n","category":"function"},{"location":"api/loggers/#Loggers","page":"Loggers API","title":"Loggers","text":"Pages = [\"loggers.md\"]","category":"section"},{"location":"api/loggers/#Abstract-Types","page":"Loggers API","title":"Abstract Types","text":"","category":"section"},{"location":"api/loggers/#Logger-Structures","page":"Loggers API","title":"Logger Structures","text":"","category":"section"},{"location":"api/loggers/#Exported-Functions","page":"Loggers API","title":"Exported Functions","text":"","category":"section"},{"location":"api/loggers/#RLinearAlgebra.Logger","page":"Loggers API","title":"RLinearAlgebra.Logger","text":"Logger\n\nAn abstract supertype for structures that record the progress of a SolverRecipe applied to a coefficient matrix and constant vector.\n\n\n\n\n\n","category":"type"},{"location":"api/loggers/#RLinearAlgebra.LoggerRecipe","page":"Loggers API","title":"RLinearAlgebra.LoggerRecipe","text":"LoggerRecipe\n\nAn abstract supertype for a structure that contains pre-allocated memory for a method that records the progress of a SolverRecipe.\n\n\n\n\n\n","category":"type"},{"location":"api/loggers/#RLinearAlgebra.BasicLogger","page":"Loggers API","title":"RLinearAlgebra.BasicLogger","text":"BasicLogger <: Logger\n\nThis is a mutable struct that contains the max_it parameter and stores the error metric      in a vector. Checks convergence of the solver based on the log information.\n\nFields\n\nmax_it::Int64, The maximum number of iterations for the solver. If not specified by the  user, it is set to 3 times the number of rows in the matrix.\nthreshold_info::Union{Float64, Tuple}, The parameters used for stopping the algorithm.\ncollection_rate::Int64, the rate that history is gathered. (Note: The last value is   always recorded.)\nstopping_criterion::Function, function that evaluates the stopping criterion.\n\n\n\n\n\n","category":"type"},{"location":"api/loggers/#RLinearAlgebra.BasicLoggerRecipe","page":"Loggers API","title":"RLinearAlgebra.BasicLoggerRecipe","text":"BasicLoggerRecipe <: LoggerRecipe\n\nThis is a mutable struct that contains the max_it parameter and stores the error metric      in a vector. Checks convergence of the solver based on the log information.\n\nFields\n\nmax_it::Int64, The maximum number of iterations for the solver.\nerror::Float64, The current error metric.\nthreshold_info::Union{Float64, Tuple}, The parameters used for stopping the algorithm.\niteration::Int64, the current iteration of the solver.\nrecord_location::Int64, the location in the history vector of the most recent entry.\ncollection_rate::Int64, the rate that history is gathered. (Note: The last value is   always recorded.)\nconverged::Bool, A boolean indicating whether the stopping criterion is satisfied.\nStoppingCriterion::Function, function that evaluates the stopping criterion.\nhist:AbstractVector, vector that contains the history of the error metric.\n\n\n\n\n\n","category":"type"},{"location":"api/loggers/#RLinearAlgebra.complete_logger","page":"Loggers API","title":"RLinearAlgebra.complete_logger","text":"complete_logger(logger::Logger)\n\nA function that generates a LoggerRecipe given the      arguments.\n\nArguments\n\nlogger::Logger, a user-specified logging method.\n\nReturns\n\nA LoggerRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/loggers/#RLinearAlgebra.update_logger!","page":"Loggers API","title":"RLinearAlgebra.update_logger!","text":"update_logger!(logger::LoggerRecipe, err::Float64, iteration::Int64)\n\nA function that updates the LoggerRecipe in place given      arguments.\n\nArguments\n\nlogger::LoggerRecipe, a fully initialized realization for a    logging method for a specific linear or least squares solver.\nerr::Real, an error value to be logged. \niteration::Int64, the iteration of the solver. \n\nReturns\n\nPerforms an inplace update to the LoggerRecipe and returns nothing.\n\n\n\n\n\n","category":"function"},{"location":"api/loggers/#RLinearAlgebra.reset_logger!","page":"Loggers API","title":"RLinearAlgebra.reset_logger!","text":"reset_logger!(logger::LoggerRecipe)\n\nA function that resets the LoggerRecipe in place.\n\nArguments\n\nlogger::LoggerRecipe, a fully initialized realization for a    logging method for a specific linear or least squares solver.\n\nReturns\n\nPerforms an inplace update to the LoggerRecipe and returns nothing.\n\n\n\n\n\n","category":"function"},{"location":"api/loggers/#RLinearAlgebra.threshold_stop","page":"Loggers API","title":"RLinearAlgebra.threshold_stop","text":"threshold_stop(log::BasicLoggerRecipe)\n\nFunction that takes an input threshold and stops when the most recent entry in the history vector is less than the threshold.\n\nArguments\n\nlog::LoggerRecipe, a structure containing the logger information\n\nBool\n\nReturns a Bool indicating if the stopping threshold is satisfied.\n\n\n\n\n\n","category":"function"},{"location":"api/compressors/#Compressors-API","page":"Compressors API","title":"Compressors API","text":"Pages = [\"compressors.md\"]","category":"section"},{"location":"api/compressors/#Abstract-Types","page":"Compressors API","title":"Abstract Types","text":"","category":"section"},{"location":"api/compressors/#Compressor-Structures","page":"Compressors API","title":"Compressor Structures","text":"","category":"section"},{"location":"api/compressors/#Exported-Functions","page":"Compressors API","title":"Exported  Functions","text":"","category":"section"},{"location":"api/compressors/#Internal-Functions","page":"Compressors API","title":"Internal Functions","text":"","category":"section"},{"location":"api/compressors/#RLinearAlgebra.Compressor","page":"Compressors API","title":"RLinearAlgebra.Compressor","text":"Compressor\n\nAn abstract supertype for structures that contain user-controlled parameters corresponding to techniques that compress a matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.CompressorRecipe","page":"Compressors API","title":"RLinearAlgebra.CompressorRecipe","text":"CompressorRecipe\n\nAn abstract supertype for structures that contain both the user-controlled parameters in the Compressor and the memory allocations necessary for applying the compression technique to a particular set of matrices and vectors.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.CompressorAdjoint","page":"Compressors API","title":"RLinearAlgebra.CompressorAdjoint","text":"CompressorAdjoint{S<:CompressorRecipe}\n\nA structure for the adjoint of a compression recipe.\n\nFields\n\nParent::CompressorRecipe, the CompressorRecipe the adjoint is being applied to.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.Cardinality","page":"Compressors API","title":"RLinearAlgebra.Cardinality","text":"Cardinality\n\nAn abstract type for types that specify whether a compressor will be applied from the left or the right.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.Left","page":"Compressors API","title":"RLinearAlgebra.Left","text":"Left <: Cardinality\n\nA struct indicating matrix multiplication from the left.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.Right","page":"Compressors API","title":"RLinearAlgebra.Right","text":"Right <: Cardinality\n\nA struct indicating matrix multiplication from the right.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.Undef","page":"Compressors API","title":"RLinearAlgebra.Undef","text":"Undef <: Cardinality\n\nA struct indicating matrix multiplication is undefined.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.CountSketch","page":"Compressors API","title":"RLinearAlgebra.CountSketch","text":"CountSketch <: Compressor\n\nAn implementation of the count sketch compression method. See additional details in  [7] Section 2.1, in which the CountSketch matrix is equivalently defined as sparse  embedding matrix.\n\nMathematical Description\n\nLet A be an m times n matrix that we want to compress. If we want to compress A from  the left (i.e., we reduce the number of rows), then we construct a Count Sketch matrix S with  dimension s times m, where s is the user-specified compression dimension. Each column of  S is generated independently by the following steps:\n\nRandomly select an integer between 1 and s to determine the row position of the nonzero entry.\nAssign this entry a value of either +1 or -1, chosen uniformly at random.\nSet all the other entries in the column to zero.\n\nAs a result, each column of S has exactly one nonzero element.\n\nIf A is compressed from the right, then we construct a Count Sketch matrix S with dimension  n times s, where s is the user-specified compression dimension. Each row of S is  generated independently using the following steps:\n\nRandomly select an integer between 1 and s to determine the column position of the nonzero entry.\nAssign this entry a value of either +1 or -1, chosen uniformly at random.\nSet all other entries in the row to zero.\n\nIn this case, each row of S has exactly one nonzero entry.  The compressed matrix is then formed by multiplying S A (for left compression) or A S (for right compression).\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().\ncompression_dim::Int64, the target compression dimension. Referred to as s in the   mathematical description.\ntype::Type{<:Number}, the type of the elements in the compressor.\n\nConstructor\n\nCountSketch(;carinality=Left(), compression_dim=2, type=Float64)\n\nKeywords\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().   By default Left() is chosen.\ncompression_dim, the target compression dimension. Referred to as s in the   mathemtical description. By default this is set to 2.\ntype::Type{<:Number}, the type of the elements in the compressor. By default is set   to Float64.\n\nReturns\n\nA CountSketch object.\n\nThrows\n\nArgumentError if compression_dim is non-positive\nArgumentError if Undef() is taken as the input for cardinality\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.CountSketchRecipe","page":"Compressors API","title":"RLinearAlgebra.CountSketchRecipe","text":"CountSketchRecipe <: CompressorRecipe\n\nThe recipe containing all allocations and information for the CountSketch compressor.\n\nFields\n\ncardinality::C where C<:Cardinality, the cardinality of the compressor. The    value is either Left() or Right().\ncompression_dim::Int64, the target compression dimension.\nn_rows::Int64, the number of rows of the compression matrix.\nn_cols::Int64`, the number of columns of the compression matrix.\nmat::SparseMatrixCSC, the compression matrix stored in a sparse form.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.FJLT","page":"Compressors API","title":"RLinearAlgebra.FJLT","text":"FJLT <: Compressor\n\nAn implementation of the Fast Johnson-Lindenstrauss Transform method. This technique applies a sparse matrix, a Walsh-Hadamard transform, and a diagonal sign matrix to produce a sketch.  See [8] for additional details.\n\nMathematical Description\n\nLet A be an m times n matrix that we want to compress. If we want to compress A from the left (i.e., we reduce the number of rows), then we create a matrix, S, with dimension s times m where s is the compression dimension that is supplied by the user. Here S=KHD where \n\nK is a sparse matrix with  with dimension s times m, where each entry has    probability q of being non-zero, and, if it is non-zero, then its value is    drawn from an independent normal distribution with mean 0 and variance 1q;\nH is a Hadamard matrix of dimension m times m, which is implicitly applied    through the fast Walsh-Hadamard transform;\nD of is a diagonal matrix of dimension m times m with entries given by    independent Rademacher variables.\n\nIf we want to compress A from the right (i.e., we reduce the number of columns), then  we would apply S=DHK from the right where the dimensions of the matrices are adjusted  to reflect the number of columns in A.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().\ncompression_dim::Int64, the target compression dimension. Referred to as s in the   mathematical description.\nblock_size::Int64, the number of vectors in the padding matrix.\nsparsity::Int64, the desired sparsity of the matrix K.\ntype::Type{<:Number}, the type of the elements in the compressor.\n\nConstructor\n\nFJLT(;\n    cardinality=Left(),\n    compression_dim::Int64=2,\n    block_size::Int64=10,\n    sparsity::Float64=0.0,\n    type::Type{N}=Float64,\n) where {N<:Number}\n\nKeywords\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().   By default Left() is chosen.\ncompression_dim::Int64, the target compression dimension. Referred to as s in the   mathematical description. By default this is set to 2.\nblock_size::Int64, the number of vectors in the padding matrix.\nsparsity::Int64, the desired sparsity of the matrix K, by default sparsity will be    set to be minleft(14 log(n)^2  m 1right), see [8].\ntype::Type{<:Number}, the type of elements in the compressor.\n\nReturns\n\nA FJLT object.\n\nThrows\n\nArgumentError if compression_dim is non-positive, if sparsity is not in 01,   or if block_size is non-positive.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.FJLTRecipe","page":"Compressors API","title":"RLinearAlgebra.FJLTRecipe","text":"FJLTRecipe{C<:Cardinality, S<:SparseMatrixCSC, M<:AbstractMatrix} <: CompressorRecipe\n\nThe recipe containing all allocations and information for the FJLT compressor.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to   be applied to a target matrix or operator. Values allowed are Left() or Right().\nn_rows::Int64, the number of rows of the compression matrix.\nn_cols::Int64, the number of columns of the compression matrix.\nsparsity:Float64, the sparsity, q, of the sparse component, K.\nscale::Float64, the factor to ensure the isopmorphism of the sketch.\nop::SparseMatrixCSC, the sparse matrix K in the mathematical description.\nsigns::BitVector, the vector of signs where 0 indicates negative one and 1 indicates   positive one. \npadding::AbstractMatrix, the matrix containing the padding for the matrix being sketched.\n\nConstructor\n\nFJLTRecipe(\n    compression_dim::Int64, \n    block_size::Int64,\n    cardinality::C where {C<:Cardinality},\n    sparsity::Float64,\n    A::AbstractMatrix, \n    type::Type{<:Number}\n)\n\nKeywords\n\ncompression_dim, the target compression dimension. Referred to as s in the   mathemtical description. By default this is set to 2.\nblock_size::Int64, the number of columns in the padding memory buffer.\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().   By default Left() is chosen.\nsparsity::Vector{Number}, the expected sparsity of the Sparse operator matrix.\nA::AbstractMatrix, the matrix being compressed.\ntype::Type{<:Number}, the type of elements in the compressor.\n\ninfo: Info\nIf the sparsity parameter is set to 0.0, then the sparsity will be set to  minleft(14 log(n)^2  m 1right), see [8].\n\nReturns\n\nA FJLTRecipe object.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.Gaussian","page":"Compressors API","title":"RLinearAlgebra.Gaussian","text":"Gaussian <: Compressor\n\nA specification for a Gaussian compressor.\n\nMathematical Description\n\nLet A be an m times n matrix that we want to compress.\n\nIf we want to compress A from the left (i.e., we reduce the number of rows), then we create a Gaussian sketch matrix, S, with dimension s times m where s is the compression dimension that is supplied by the user. Each entry of S is generated independently following N(0, 1/s), namely, a Gaussian distribution with mean being zero and variance being 1 divided by the compression dimension.\n\nIf A is compressed from the right, then we create a Gaussian sketch matrix, S, with dimension n times s, where s is the compression dimension that is supplied by the user. Each entry of S is generated independently following N(0, 1/s), namely, a Gaussian distribution with mean being zero and variance being 1 divided by the compression dimension.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().\ncompression_dim::Int64, the target compression dimension. Referred to as s in    the mathematical description.\ntype::Type{<:Number}, the type of the elements in the compressor.\n\nConstructor\n\nGaussian(;cardinality=Left(), compression_dim=2, type=Float64)\n\nArguments\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().   By default Left() is chosen.\ncompression_dim::Int64, the target compression dimension. Referred to as s in    the mathemtical description. By default this is set to 2.\ntype::Type{<:Number}, the type of elements in the compressor.\n\nReturns\n\nA Gaussian object.\n\nThrows\n\nArgumentError if compression_dim is non-positive\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.GaussianRecipe","page":"Compressors API","title":"RLinearAlgebra.GaussianRecipe","text":"GaussianRecipe <: CompressorRecipe\n\nThe recipe containing all allocations and information for the Gaussian compressor.\n\nFields\n\ncardinality::C where C<:Cardinality, the cardinality of the compressor. The\n\nvalue is either Left() or Right().\n\ncompression_dim::Int64, the target compression dimension.\nn_rows::Int64, the number of rows of the compression matrix.\nn_cols::Int64, the number of columns of the compression matrix.\nscale::Number, the standard deviation of Gaussian distribution during the \n\ncompression matrix generation.\n\nop::Matrix{Float64}, the Gaussian compression matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.Identity","page":"Compressors API","title":"RLinearAlgebra.Identity","text":"Identity <: Compressor\n\nAn implementation of a compressor that returns the original matrix.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to   be applied to a target matrix or operator. Values allowed are Left() or Right().\n\nConstructor\n\nIdentity(;cardinality=Left())\n\nKeywords\n\ncardinality::Cardinality, the direction the compression matrix is intended to   be applied to a target matrix or operator. Values allowed are Left() or Right().\n\nReturns\n\nA Identity object.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.IdentityRecipe","page":"Compressors API","title":"RLinearAlgebra.IdentityRecipe","text":"IdentityRecipe <: CompressorRecipe\n\nThe recipe containing all allocations and information for the Identity compressor.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to   be applied to a target matrix or operator. Values allowed are Left() or Right().\nn_rows::Int64, the number of rows of the compression matrix.\nn_cols::Int64, the number of columns of the compression matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.Sampling","page":"Compressors API","title":"RLinearAlgebra.Sampling","text":"Sampling <: Compressor\n\nThis method subsets the rows  or columns of a matrix according to a user-supplied distribution. The size of the  subset is also provided by the user.\n\nMathematical Description\n\nLet A be an m times n matrix that we want to compress.\n\nIf we want to compress A from the left (i.e., we reduce the number of rows), then we create an index set to contain all the indices of selected rows. The indices are  chosen by sampling over all the rows with the user-specified distribution in the  distribution field.\n\nIf A is compressed from the right (i.e., we reduce the number of columns), then we create an index set to contain all the indices of selected columns. The indices  are chosen by sampling over all the columns with the user-specified distribution  in the distribution field.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().\ncompression_dim::Int64, the target compression dimension.\ndistribution::Distribution, the distribution being used to assign probability weights   on the indices.\n\nConstructor\n\nSampling(;cardinality = Left(), compression_dim = 2, distribution)\n\nArguments\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().   By default Left() is chosen.\ncompression_dim::Int64, the target compression dimension. By default this is set to 2.\ndistribution::Distribution, the distribution being used to assign probability weights   on the indices. By default this is set as Uniform distribution.\n\nReturns\n\nA Sampling object.\n\nThrows\n\nArgumentError if compression_dim is non-positive\nArgumentError if Undef() is taken as the input for cardinality\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.SamplingRecipe","page":"Compressors API","title":"RLinearAlgebra.SamplingRecipe","text":"SamplingRecipe{C<:Cardinality} <: CompressorRecipe\n\nThe recipe containing all allocations and information for the sampling compressor. \n\nFields\n\ncardinality::Cardinality, the cardinality of the compressor. The   value is either Left() or Right().\ncompression_dim::Int64, the target compression dimension.\nn_rows::Int64, number of rows of compression matrix.\nn_cols::Int64, number of columns of compression matrix.\ndistribution_recipe::DistributionRecipe, the user-specified distribution recipe.\nidx::Vector{Int64}, the index set that contains all the chosen indices.\nidx_v::SubArray, the view of the idx.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.SparseSign","page":"Compressors API","title":"RLinearAlgebra.SparseSign","text":"SparseSign <: Compressor\n\nAn implementation of the sparse sign compression method. This method forms a sparse matrix with a fixed number of non-zeros per row or column depending on the direction that the compressor is being applied. See Section 9.2 of [5] for additional details.\n\nMathematical Description\n\nLet A be an m times n matrix that we want to compress. If we want to compress A from the left (i.e., we reduce the number of rows), then we create a sparse sign matrix, S, with dimension s times m where s is the compression dimension that is supplied by the user. In this case, each column of S is generated independently by the following steps:\n\nRandomly choose nnz components of the the s components of the column. Note, nnz  is supplied by the user.\nFor each selected component, randomly set it either to -1sqrttextnnz or  1sqrttextnnz with equal probability.\nSet the remaining components of the column to zero.\n\nIf A is compressed from the right, then we create a sparse sign matrix, S, with dimension n times s, where s is the compression dimension that is supplied by the user. In this case, each row of S is generated independently by the following steps:\n\nRandomly choose nnz components of the s components of the row. Note, nnz  is supplied by the user.\nFor each selected component, randomly set it either to -1sqrttextnnz or  1sqrttextnnz with equal probability.\nSet the remaining components of the row to zero.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().\ncompression_dim::Int64, the target compression dimension. Referred to as s in the   mathematical description.\nnnz::Int64, the target number of nonzeros for each column or row of the spares sign   matrix.\ntype::Type{<:Number}, the type of the elements in the compressor.\n\nConstructor\n\nSparseSign(;carinality=Left(), compression_dim=2, nnz::Int64=8, type=Float64)\n\nKeywords\n\ncarinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().   By default Left() is chosen.\ncompression_dim, the target compression dimension. Referred to as s in the   mathemtical description. By default this is set to 2.\nnnz::Int64, the number of non-zeros per row/column in the sampling matrix. By default   this is set to min(compressiond_dim, 8).\ntype::Type{<:Number}, the type of elements in the compressor.\n\nReturns\n\nA SparseSign object.\n\nThrows\n\nArgumentError if compression_dim is non-positive, if nnz is exceeds   compression_dim, or if nnz is non-positive.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.SparseSignRecipe","page":"Compressors API","title":"RLinearAlgebra.SparseSignRecipe","text":"SparseSignRecipe{C<:Cardinality} <: CompressorRecipe\n\nThe recipe containing all allocations and information for the SparseSign compressor.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to\n\nbe applied to a target matrix or operator. Values allowed are Left() or Right().\n\nn_rows::Int64, the number of rows of the compression matrix.\nn_cols::Int64, the number of columns of the compression matrix.\nnnz::Int64, the number of non-zero entries in each row if cardinality==Left or the\n\nnumber of non-zero entries each column if cardinality==Right.\n\nscale::Vector{Number}, the set of values of the non-zero entries of the Spares Sign\n\ncompression matrix.\n\nop::SparseMatrixCSC, the Spares Sign compression matrix.\n\nConstructors\n\nSparseSignRecipe(\n    cardinality::C where C<:Cardinality,\n    compression_dim::Int64, \n    A::AbstractMatrix, \n    nnz::Int64, \n    type::Type{<:Number}\n)\n\nAn external constructor of SparseSignRecipe that is dispatched based on the  value of cardinality. See SparseSign for additional details. \n\nArguments\n\ncardinality::C where C<:Cardinality, the cardinality of the compressor. The    value is either Left() or Right()\ncompression_dim::Int64, the target compression dimension.\nA::AbstractMatrix, a target matrix for compression. \nnnz::Int64, the number of nonzeros in the Sparse Sign compression matrix.\ntype::Type{<:Number}, the data type for the entries of the compression matrix.\n\nReturns\n\nA SparseSignRecipe object.\n\nwarning: Use `complete_compressor`\nWhile an external constructor is provided, it is mainly for internal use. To ensure cross library compatibility please use complete_compressor for forming the SparseSignRecipe.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.SRHT","page":"Compressors API","title":"RLinearAlgebra.SRHT","text":"SRHT <: Compressor\n\nAn implementation of the Subsampled Randomized Hadamard Transform (SRHT) method. This  technique applies a subsampling matrix, a Walsh-Hadamard transform, and a diagonal sign  matrix to produce a sketch. See [9] for additional details.\n\nMathematical Description\n\nLet A be an m times n matrix that we want to compress. If we want to compress A from the left (i.e., we reduce the number of rows), then we create a matrix, S, with dimension s times m where s is the compression dimension that is supplied by the user. Here S=KHD where \n\nK is a matrix with  with dimension s times m, where the rows are made up of a    random sample of the rows of a m times m identity matrix.\nH is a Hadamard matrix of dimension m times m, which is implicitly applied    through the fast Walsh-Hadamard transform;\nD of is a diagonal matrix of dimension m times m with entries given by    independent Rademacher variables.\n\nIf we want to compress A from the right (i.e., we reduce the number of columns), then  we would apply S=DHK from the right where the dimensions of the matrices are adjusted  to reflect the number of columns in A.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().\ncompression_dim::Int64, the target compression dimension. Referred to as s in the   mathematical description.\nblock_size::Int64, the number of vectors in the padding matrix.\ntype::Type{<:Number}, the type of the elements in the compressor.\n\nConstructor\n\nSRHT(;\n    cardinality = Left(),\n    compression_dim::Int64=2,\n    block_size::Int64=10,\n    type::Type{N}=Float64\n) where {N <: Number}\n\nKeywords\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().   By default Left() is chosen.\ncompression_dim::Int64, the target compression dimension. Referred to as s in the   mathematical description. By default this is set to 2.\nblock_size::Int64, the number of vectors in the padding matrix.\ntype::Type{<:Number}, the type of elements in the compressor.\n\nReturns\n\nA SRHT object.\n\nThrows\n\nArgumentError if compression_dim is non-positive or if block_size is non-positive.\nArgumentError if Cardinality is not either Left or Right.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.SRHTRecipe","page":"Compressors API","title":"RLinearAlgebra.SRHTRecipe","text":"SRHTRecipe{C<:Cardinality, M<:AbstractMatrix} <: CompressorRecipe\n\nThe recipe containing all allocations and information for the SRHT compressor.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to   be applied to a target matrix or operator. Values allowed are Left() or Right().\nn_rows::Int64, the number of rows of the compression matrix.\nn_cols::Int64, the number of columns of the compression matrix.\nscale::Float64, the factor to ensure the isopmorphism of the sketch.\nop::Vector{Int64}, the vector of indices to be subsampled.\nsigns::BitVector, the vector of signs where 0 indicates negative one and 1 indicates   positive one. \npadding::AbstractMatrix, the matrix containing the padding for the matrix being    sketched.\n\nConstructor\n\nSRHTRecipe(\n    compression_dim::Int64,\n    block_size::Int64,\n    cardinality::Left,\n    A::AbstractMatrix,\n    type::Type{<:Number}\n)\n\nKeywords\n\ncompression_dim::Int64, the target compression dimension. Referred to as s in the   mathematical description.\nblock_size::Int64, the number of vectors in the padding matrix.\ncardinality::Left, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right().\nA::AbstractMatrix, the matrix being compressed.\ntype::Type{<:Number}, the type of elements in the compressor.\n\n\n\n\n\n","category":"type"},{"location":"api/compressors/#RLinearAlgebra.complete_compressor","page":"Compressors API","title":"RLinearAlgebra.complete_compressor","text":"complete_compressor(compressor::Compressor, x::AbstractVector)\n\nA function that generates a CompressorRecipe given the      arguments.\n\nArguments\n\ncompressor::Compressor, a user-specified compression method.\nx::AbstractVector, a vector that ususally represents a current iterate    typically used in a solver.\n\nReturns\n\nA CompressorRecipe object.\n\nThrows\n\nArgumentError if no method for completing the compressor exists    for the given arguments.\n\n\n\n\n\ncomplete_compressor(compressor::Compressor, A::AbstractMatrix)\n\nA function that generates a CompressorRecipe given the      arguments.\n\nArguments\n\ncompressor::Compressor, a user-specified compression method.\nA::AbstractMatrix, a target matrix for compression.\n\nReturns\n\nA CompressorRecipe object.\n\nThrows\n\nArgumentError if no method for completing the compressor exists    for the given arguments.\n\n\n\n\n\ncomplete_compressor(compressor::Compressor, A::AbstractMatrix, b::AbstractVector)\n\nA function that generates a CompressorRecipe given the      arguments.\n\nArguments\n\ncompressor::Compressor, a user-specified compression method.\nA::AbstractMatrix, a target matrix for compression.\nb::AbstractVector, a possible target vector for compression.\n\nReturns\n\nA CompressorRecipe object.\n\nThrows\n\nArgumentError if no method for completing the compressor exists    for the given arguments.\n\n\n\n\n\ncomplete_compressor(\n    compressor::Compressor, \n    x::AbstractVector\n    A::AbstractMatrix, \n    b::AbstractVector, \n)\n\nA function that generates a CompressorRecipe given the      arguments.\n\nArguments\n\ncompressor::Compressor, a user-specified compression method.\nx::AbstractVector, a vector that ususally represents a current iterate    typically used in a solver.\nA::AbstractMatrix, a target matrix for compression.\nb::AbstractVector, a possible target vector for compression.\n\nReturns\n\nA CompressorRecipe object.\n\nThrows\n\nArgumentError if no method for completing the compressor exists    for the given arguments.\n\n\n\n\n\n","category":"function"},{"location":"api/compressors/#RLinearAlgebra.update_compressor!","page":"Compressors API","title":"RLinearAlgebra.update_compressor!","text":"update_compressor!(S::CompressorRecipe)\n\nA function that updates the CompressorRecipe in place given      arguments.\n\nArguments\n\nS::CompressorRecipe, a fully    initialized realization for a compression method for a specific matrix or collection    of matrices and vectors.\n\nReturns\n\nnothing\n\nThrows\n\nArgumentError if no method exists for updating the compressor    exists.\n\n\n\n\n\nupdate_compressor!(S::CompressorRecipe, A::AbstractMatrix)\n\nA function that updates the CompressorRecipe in place given      arguments.\n\nArguments\n\nS::CompressorRecipe, a fully    initialized realization for a compression method for a specific matrix or collection    of matrices and vectors.\nA::AbstractMatrix, a target matrix for compression.\n\nReturns\n\nnothing\n\nThrows\n\nArgumentError if no method exists for updating the compressor    exists.\n\n\n\n\n\nupdate_compressor!(S::CompressorRecipe, A::AbstractMatrix, b::AbstractVector)\n\nA function that updates the CompressorRecipe in place given      arguments.\n\nArguments\n\nS::CompressorRecipe, a fully    initialized realization for a compression method for a specific matrix or collection    of matrices and vectors.\nA::AbstractMatrix, a target matrix for compression.\nb::AbstractVector, a possible target vector for compression.\n\nReturns\n\nnothing\n\nThrows\n\nArgumentError if no method exists for updating the compressor    exists.\n\n\n\n\n\nupdate_compressor!(\n    S::CompressorRecipe, \n    A::AbstractMatrix, \n    b::AbstractVector,\n    x::AbstractMatrix\n)\n\nA function that updates the CompressorRecipe in place given      arguments.\n\nArguments\n\nS::CompressorRecipe, a fully    initialized realization for a compression method for a specific matrix or collection    of matrices and vectors.\nx::AbstractVector, a vector that ususally represents a current iterate    typically used in a solver.\nA::AbstractMatrix, a target matrix for compression.\nb::AbstractVector, a possible target vector for compression.\n\nReturns\n\nnothing\n\nThrows\n\nArgumentError if no method exists for updating the compressor    exists.\n\n\n\n\n\n","category":"function"},{"location":"api/compressors/#RLinearAlgebra.left_mul_dimcheck","page":"Compressors API","title":"RLinearAlgebra.left_mul_dimcheck","text":"left_mul_dimcheck(C::AbstractMatrix, S::CompressorRecipe, A::AbstractMatrix)\n\nA function that checks the compatibility of arguments for      multiplication from the left.\n\nArguments\n\nC::AbstractArray, a AbstractArray where the output will be stored.\nS::Union{CompressorRecipe, ApproximatorRecipe}, a fully    initialized realization for a compression or approximator method for a    specific AbstractArray or operator.\nA::AbstractArray, a target AbstractArray for compression.\n\nReturns\n\nnothing\n\nThrows\n\nDimensionMismatch if dimensions of arguments are not compatible for   multiplication.\n\n\n\n\n\nleft_mul_dimcheck(C::AbstractMatrix, S::CompressorAdjoint, A::AbstractMatrix)\n\nA function that checks the compatibility of arguments for      multiplication from the left.\n\nArguments\n\nC::AbstractArray, a AbstractArray where the output will be stored.\nS::Union{CompressorAdjoint, ApproximatorAdjoint}, the    representation of an adjoint of a compression or approximator operator.\nA::AbstractArray, a target AbstractArray for compression.\n\nReturns\n\nnothing\n\nThrows\n\nDimensionMismatch if dimensions of arguments are not compatible for   multiplication.\n\n\n\n\n\n","category":"function"},{"location":"api/compressors/#RLinearAlgebra.right_mul_dimcheck","page":"Compressors API","title":"RLinearAlgebra.right_mul_dimcheck","text":"right_mul_dimcheck(C::AbstractMatrix, A::AbstractMatrix, S::CompressorRecipe)\n\nA function that checks the compatibility of arguments for      multiplication from the right.\n\nArguments\n\nC::AbstractArray, a AbstractArray where the output will be stored.\nA::AbstractArray, a target AbstractArray for compression.\nS::Union{CompressorRecipe, ApproximatorRecipe}, a fully    initialized realization for a compression or approximator method for a    specific AbstractArray or operator.\n\nReturns\n\nnothing\n\nThrows\n\nDimensionMismatch if dimensions of arguments are not compatible for   multiplication.\n\n\n\n\n\nright_mul_dimcheck(C::AbstractMatrix, A::AbstractMatrix, S::CompressorAdjoint)\n\nA function that checks the compatibility of arguments for      multiplication from the right.\n\nArguments\n\nC::AbstractArray, a AbstractArray where the output will be stored.\nA::AbstractArray, a target AbstractArray for compression.\nS::Union{CompressorAdjoint, ApproximatorAdjoint}, the    representation of an adjoint of a compression or approximator operator.\n\nReturns\n\nnothing\n\nThrows\n\nDimensionMismatch if dimensions of arguments are not compatible for   multiplication.\n\n\n\n\n\n","category":"function"},{"location":"api/compressors/#RLinearAlgebra.sparse_idx_update!","page":"Compressors API","title":"RLinearAlgebra.sparse_idx_update!","text":"sparse_idx_update!(\n    values::Vector{Int64}, \n    max_sample_val::Int64, \n    n_samples::Int64, \n    sample_size::Int64\n)\n\nImplicitly splits values into n_samples components of size sample_size.  On each component, replaces the entries of each component with a random sample  without replacement of size sample_size from the set 1:max_sample_val.\n\nwarn: Warn\nvalues should have length equal to sample_size*n_samples, but this  is not checked. \n\nArguments\n\nvalues::Vector{Int64}, a vector containing samples from 1:max_sample_val.\nmax_sample_val::In64, implicitly supplies the set from which to sample,   1:max_sample_val.\nn_samples::Int64, the number of components that values is implicitly split into. \nsample_size::Int64, the size each component that values is split into.\n\nReturns\n\nnothing\n\n\n\n\n\n","category":"function"},{"location":"api/compressors/#RLinearAlgebra.fwht!","page":"Compressors API","title":"RLinearAlgebra.fwht!","text":"fwht!(x::AbstractVector, signs::BitVector; scaling::Int64 = 1)\n\nPerforms an in-place Fast Walsh Hadamard Transform on the vector x.   signs allows the user to input a boolean vector that flips the signs of the entries  of the vector x before applying the transform. scaling allows the user to scale the  result of the transform. Choosing a scaling of 1/sqrt{size(x)} will result in the FWHT  being an orthogonal transform.\n\nArguments\n\nx::AbstractVector, the vector the FJLT will be applied to.\nsigns::Vector{Bool}, whether the sign of each entry is positive or negative.\n\nKeywords\n\nscaling::Number, how much the vector is scaled, by default this is 1.\n\nReturns\n\nnothing\n\n\n\n\n\n","category":"function"},{"location":"api/sub_solvers/#SubSolvers","page":"SubSolvers API","title":"SubSolvers","text":"Pages = [\"sub_solvers.md\"]","category":"section"},{"location":"api/sub_solvers/#Abstract-Types","page":"SubSolvers API","title":"Abstract Types","text":"","category":"section"},{"location":"api/sub_solvers/#SubSolver-Structures","page":"SubSolvers API","title":"SubSolver Structures","text":"","category":"section"},{"location":"api/sub_solvers/#Exported-Functions","page":"SubSolvers API","title":"Exported Functions","text":"","category":"section"},{"location":"api/sub_solvers/#RLinearAlgebra.SubSolver","page":"SubSolvers API","title":"RLinearAlgebra.SubSolver","text":"SubSolver\n\nAn abstract supertype for structures specifying solution methods for a linear system or least squares problem.\n\n\n\n\n\n","category":"type"},{"location":"api/sub_solvers/#RLinearAlgebra.SubSolverRecipe","page":"SubSolvers API","title":"RLinearAlgebra.SubSolverRecipe","text":"SubSolverRecipe\n\nAn abstract supertype for structures with pre-allocated memory for methods that solve a linear system or least squares problem.\n\n\n\n\n\n","category":"type"},{"location":"api/sub_solvers/#RLinearAlgebra.LQSolver","page":"SubSolvers API","title":"RLinearAlgebra.LQSolver","text":"LQSolver <: SubSolver\n\nA type containing information relevant to solving the linear subsystems created by the      Solver routines with the LQ factorization. As there are no user controlled parameters,      if the user wishes to use this method they can simply specify LQSolver().\n\n\n\n\n\n","category":"type"},{"location":"api/sub_solvers/#RLinearAlgebra.LQSolverRecipe","page":"SubSolvers API","title":"RLinearAlgebra.LQSolverRecipe","text":"LQSolverRecipe <: SubSolverRecipe{M<:AbstractArray}\n\nA mutable type containing informtation relevant to solving the linear subsytems created by      the Solver routines with the LQ factorization.\n\nFields\n\nA::M, The matrix in the linear system that will be solved with the LQ solver.\n\n\n\n\n\n","category":"type"},{"location":"api/sub_solvers/#RLinearAlgebra.QRSolver","page":"SubSolvers API","title":"RLinearAlgebra.QRSolver","text":"QRSolver <: SubSolver\n\nA type containing information relevant to solving the linear subsystems created by the      Solver routines with the QR factorization. As there are no user controlled parameters,      if the user wishes to use this method they can simply specify QRSolver().\n\nFields\n\nNone\n\n\n\n\n\n","category":"type"},{"location":"api/sub_solvers/#RLinearAlgebra.QRSolverRecipe","page":"SubSolvers API","title":"RLinearAlgebra.QRSolverRecipe","text":"QRSolverRecipe{M<:AbstractArray} <: SubSolverRecipe\n\nA mutable type containing information relevant to solving the linear subsystems created by      the Solver routines with the QR factorization.\n\nFields\n\nA::M, The matrix in the linear system that will be solved with the QR solver.\n\n\n\n\n\n","category":"type"},{"location":"api/sub_solvers/#RLinearAlgebra.complete_sub_solver","page":"SubSolvers API","title":"RLinearAlgebra.complete_sub_solver","text":"complete_sub_solver(solver::SubSolver, A::AbstractArray)\n\nA function that generates a SubSolverRecipe given the      arguments.\n\nArguments\n\nsolver::SubSolver, a user-specified sub-solving method.\nA::AbstractArray, a coefficient matrix or vector. \n\nReturns\n\nA SubSolverRecipe object.\n\n\n\n\n\ncomplete_sub_solver(solver::SubSolver, A::AbstractArray, b::AbstractArray)\n\nA function that generates a SubSolverRecipe given the      arguments.\n\nArguments\n\nsolver::SubSolver, a user-specified sub-solving method.\nA::AbstractArray, a coefficient matrix or vector. \nb::AbstractArray, a constant matrix or vector. \n\nReturns\n\nA SubSolverRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/sub_solvers/#RLinearAlgebra.update_sub_solver!","page":"SubSolvers API","title":"RLinearAlgebra.update_sub_solver!","text":"update_sub_solver!(solver::SubSolverRecipe, A::AbstractArray)\n\nA function that updates the SubSolver in place given      arguments.\n\nArguments\n\nsolver::SubSolverRecipe, a fully initialized realization for a   linear sub-solver.\nA::AbstractArray, a coefficient matrix or vector. \n\nReturns\n\nModifies the SubSolverRecipe in place given the arguments.and returns nothing.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/consistent_system/configuring_kaczmarz/#Configuring-a-Basic-Logger-for-the-Generalized-Kaczmarz-Solver","page":"Configuring a Basic Logger for the Generalized Kaczmarz Solver","title":"Configuring a Basic Logger for the Generalized Kaczmarz Solver","text":"The generalized Kaczmarz solver solver [6] is specified by five quantities:\n\nA Compressor\nA Logger\nA SolverError\nA SubSolver\nAn over-relaxation parameter in (02\n\nHere, we demonstrate how to configure the BasicLogger. The BasicLogger has three arguments:\n\nthe maximum number of iterations (max_it) to run the generalized Kaczmarz solver;\na threshold for the error that terminates the solver when the error drops below    this value;\nand the interval of iterates at which to log the error. \n\nBelow is an example for specifying the BasicLogger.\n\nlogger = BasicLogger(\n    max_it = 500,           #Maximum of 500 iterations\n    threshold = 1e-6,       #Error threshold of 1e-6\n    collection_rate = 5     #Records error at every fifth iterate\n)","category":"section"},{"location":"manual/introduction/#A-library-for-exploring-Randomized-Linear-Algebra","page":"Introduction","title":"A library for exploring Randomized Linear Algebra","text":"If you are here, you probably know that Linear Algebra is foundational to data science, scientific computing, and AI. You also probably know Linear Algebra routines dominate the  computational cost of many of the algorithms in these fields. Thus, improving the  scalability of these algorithms requires more scalable Linear Algebra techniques.\n\nRandomized Linear Algebra is an exciting new approach to classical linear algebra problems  that offers strong improvements in scalability. In general, Randomized Linear Algebra  techniques achieve this improved scalability by forming a compressed representation of a  matrix and performing operations on that compressed form. In some circumstances operating on this compressed form can offer profound speed-ups as can seen in the following example  where a technique known as the RandomizedSVD (see [1])  is used to compute a rank-20 approximation to 3000 times 3000 matrix  A in place of a truncated SVD. Compared to computing the SVD and  truncating it, the RandomizedSVD is 100 times faster and just as accurate  as the truncated SVD.\n\nusing RLinearAlgebra\nusing LinearAlgebra\n\n# Generate a rank-20 matrix\nA = randn(3000, 20) * randn(20, 3000);\n\n@time U,S,V = svd(A);\n#    4.566639 seconds (13 allocations: 412.354 MiB, 0.92% gc time)\n\n# Form the RandomizedSVD data structure\ntechnique = RandSVD(\n    compressor = Gaussian(compression_dim = 22,  cardinality = Right()) \n)\n\n# Take the RandomizedSVD of A\n@time rec = rapproximate(technique, A);\n#    0.050950 seconds (39 allocations: 5.069 MiB)\n\n# Take the norm of the difference between the RandomizedSVD and TrunctatedSVD at rank 22\nnorm(rec.U * Diagonal(rec.S) * rec.V' - U[:,1:22] * Diagonal(S[1:22]) * (V[:, 1:22])')\n# 6.914995919005829e-11\n\nRandomized Linear Algebra is a fast growing field with a myriad of new methods being  proposed every year. Because randomized linear algebra methods are based around similar  sub-routines many of the innovations could offer improvements to established techniques. Unfortunately, most implementations of these techniques are static making testing the  effectiveness of innovations on previous techniques challenging. RLinearAlgebra.jl aims to  make incorporating new innovations into established randomized linear algebra techniques easy.\n\nIn particular, RLinearAlgebra.jl leverages a modular design to allow you  to easily test Randomized Linear Algebra routines under a wide-range of parameter choices.   RLinearAlgebra.jl provides routines for two core Linear Algebra tasks: finding a solution to a linear system via Ax=b or min_x Ax - b and forming a low rank  approximation to a matrix, hat A where hat A approx A. The solution to a linear system appears everywhere: Optimization, Tomography, Statistics, Scientific Computing,  Machine Learning, etc. The low-rank approximation problem has only become more relevant in  recent years owing to the drastic increase in matrix sizes. It has been widely used in  Statistics via PCA, but also has become increasingly more relevant.\n\nThis manual will walk you through the use of the RLinearAlgebra.jl library. The remainder  of this section will be focused on providing an overview of the common design elements in  the library, and information about how to get started using the library.","category":"section"},{"location":"manual/introduction/#Overview-of-the-Library","page":"Introduction","title":"Overview of the Library","text":"You can think of using RLinearAlgebra.jl as being a producer on  Chopped,  the long running Food Network cooking competition.  For those unfamiliar, the show takes place in three rounds, where one of four contestants  get eliminated at the end each round. In each round, the producers provide the contestants with a fix set of ingredients  (often rather unconventional ones at that) and a general category of food (e.g. appetizer, entree, or dessert) that the contestants then have to use in a recipe that they prepare for a panel of judges.\n\nRLinearAlgebra.jl gives you as the user the fun job of deciding which ingredients  (techniques) you want to use to solve your linear system, compress your matrix/vector,  or form an approximation of your matrix. Then, once you specify that information, you  can start the clock by calling rsolve or rapproximate, with information about your  matrix/linear system and watch RLinearAlgebra.jl do the rest. Behind the scenes  it calls all the  complete_[technique] functions that will generate recipe data  structures that have all the necessary preparations (preallocations) for handling your  proposed task. Then once the preparations are done, RLinearAlgebra follows its designed  recipes to cook-up a solution to your problem. \n\nWith this analogy of how RLinearAlgebra.jl works, the next two sections provide an overview over the two key data structures in RLinearAlgebra.jl, the technique structures (your  ingredients) and the recipe structures (what RLinearAlgebra.jl creates to perform your task).","category":"section"},{"location":"manual/introduction/#The-Technique-Types-(The-Ingredients)","page":"Introduction","title":"The Technique Types (The Ingredients)","text":"With an understanding of the basic structures in the library, one may wonder, what  types of techniques are there? First, there are the techniques for solving the linear  system, Solvers, and techniques for forming a low-rank approximation to a matrix,  Approximators. Both Solvers and Approximators achieve speedups by working on  compressed forms (often known as sketched or sampled) of the linear system or matrix,  techniques that compress the linear system are known as Compressors.  Aside from these global techniques, there are also techniques that are specific to  Solvers, which include: \n\nSubSolvers, techniques that solve the inner (compressed) linear system.\nLoggers, techniques that log information and determine whether a stopping criterion has  been met.\nSolverError, a technique that computes the error of a current iterate of a solver.  \n\nSimilarly, Approximators have their own specific techniques, which include:\n\nApproximatorError, a technique that computes the error of an Approximator.\n\nWith all these technique structures, you may be wondering, what functions can I call on these structures? Well, the answer is not many. As is  summarized in the following table.  \n\nTechnique Parent Technique Function Calls\nApproximator None complete_approximator,rapproximate\nCompressor None complete_compressor\nSolver None complete_solver, rsolve\nApproximatorError Approximator complete_approximator_error\nLogger Solver complete_logger\nSolverError Solver complete_solver_error\nSubSolver Solver complete_sub_solver\n\nFrom the above table we can see that all you are able to do (unless you are using  an Approximator or a Solver) is complete the technique. The reason being that all the  technique structures contain only information about algorithmic parameters that require no  information about the linear system. The recipes on the other hand have all the information  required to execute a technique including the required pre-allocated memory. We determine the  preallocations for the Recipes by merging the parameter information of the technique  structures with the matrix and linear system information via the complete_[technique]  functions, which is the only function that you can call when you have a technique structure.  There is a special exception for rsolve and rapproximate because they implicitly call  all the necessary completes to form the appropriate recipe. The bottom line is that do  anything useful you will need a recipe.","category":"section"},{"location":"manual/introduction/#The-Recipe-Types","page":"Introduction","title":"The Recipe Types","text":"Every technique can be transformed into a recipe. As has been stated before, what makes the  recipes different is that they contain all the required memory allocations. These  allocations can only be determined from once the matrix is known. As a user,  all you have to know is that as soon as you have a recipe you can do a lot. As can be seen  in the following table.\n\nTechnique Recipe Parent Recipe Function Calls\nApproximatorRecipe None mul!, rapproximate!\nCompressorRecipe None mul!,update_compressor!\nSolverRecipe None rsolve!\nApproximatorErrorRecipe Approximator compute_approximator_error\nLoggerRecipe Solver reset_logger!, update_logger!\nSolverErrorRecipe Solver compute_error\nSubSolverRecipe Solver update_sub_solver!,ldiv!\n\nInstead of providing  a different function for each method associated with these tasks, RLinearAlgebra.jl  leverages the multiple-dispatch functionality of Julia to allow all linear systems and  least squares problems to be solved calling the function  rsolve(solver::Solver, x::AbstractVector, A::AbstractMatrix, b::AbstractVector)  and all matrices to be approximated by calling the function  rapproximate(approximator::Approximator, A::AbstractMatrix). Under this design, changing  the routine for solving your linear system or approximate your matrix is as  simple as changing thesolver or approximator arguments. ","category":"section"},{"location":"manual/introduction/#Installing-RLinearAlgebra","page":"Introduction","title":"Installing RLinearAlgebra","text":"Currently, RLinearAlgebra.jl is not registered in Julia's official package registry. There  are two main ways of installing RLinearAlgebra.jl. The preferred way of doing it is through the local registry. You can install this approach by writing in the REPL:\n\n] registry add https://github.com/numlinalg/NumLingAlg\nadd RLinearAlgebra\n\nIt can also be installed by writing in the REPL:\n\n] add https://github.com/numlinalg/RLinearAlgebra.jl.git\n\nIt can also be cloned into a local directory and installed by:\n\ncd into the local project directory \nCall git clone https://github.com/numlinalg/RLinearAlgebra.jl.git\nRun Julia\nCall using Pkg\nCall Pkg.activate(RLinearAlgebra.jl)\nCall Pkg.instantiate()\n\nFor more information see  Using someone else's project.","category":"section"},{"location":"manual/introduction/#Using-RLinearAlgebra.jl","page":"Introduction","title":"Using RLinearAlgebra.jl","text":"For this example let's assume that we have a vector that we wish to compress using one the RLinearAlgebra.jl SparseSign compressor. To do this: \n\nLoad RLinearAlgebra.jl and generate your vector\nDefine the SparseSign technique. This requires us to specify a cardinality,  the direction we intend to apply the compressor from, and a compression_dim,   the number of entries we want in the compressed vector. In this instance we   want the cardinality to be Left() and the compression_dim = 20.\nUse the complete_compressor function to generate the SparseSignRecipe\nApply the compressor to the vector using the multiplication function\n\n# Step 1: load RLinearAlgebra.jl and generate vector\nusing RLinearAlgebra\nusing LinearAlgebra\n# Specify the size of the vector\nn = 10000\nx = rand(n)\n\n# Step 2: Define Sparse Sign Compressor\ncomp = SparseSign(compression_dim = 20, cardinality = Left())\n\n# Step 4: Define Sparse Sign Compressor Recipe\nS = complete_compressor(comp, x)\n\n# Step 4: Apply the compressor to the vector using the multiplication function\nSx = S * x\n\nnorm(Sx)\n\nnorm(x)","category":"section"},{"location":"api/distributions/#Distributions","page":"Distributions API","title":"Distributions","text":"Pages = [\"distributions.md\"]","category":"section"},{"location":"api/distributions/#Abstract-Types","page":"Distributions API","title":"Abstract Types","text":"","category":"section"},{"location":"api/distributions/#Distribution-Structures","page":"Distributions API","title":"Distribution Structures","text":"","category":"section"},{"location":"api/distributions/#Exported-Functions","page":"Distributions API","title":"Exported Functions","text":"","category":"section"},{"location":"api/distributions/#Internal-Functions","page":"Distributions API","title":"Internal Functions","text":"","category":"section"},{"location":"api/distributions/#RLinearAlgebra.Distribution","page":"Distributions API","title":"RLinearAlgebra.Distribution","text":"Distribution\n\nAn abstract supertype for structures specifying distribution for indices in sampling methods.\n\n\n\n\n\n","category":"type"},{"location":"api/distributions/#RLinearAlgebra.DistributionRecipe","page":"Distributions API","title":"RLinearAlgebra.DistributionRecipe","text":"DistributionRecipe\n\nAn abstract supertype for structures with pre-allocated memory for distribution function     sampling methods.\n\n\n\n\n\n","category":"type"},{"location":"api/distributions/#RLinearAlgebra.Uniform","page":"Distributions API","title":"RLinearAlgebra.Uniform","text":"Uniform <: Distribution\n\nUniform distribution over the row/column index set of a matrix.\n\nMathematical Description\n\nDuring the sampling, the uniform distribution is defined on the domain of row/column  indices. If it's compressing from the left, then it means every row index has the same  probability weight. If it's compressing from the right, then it means every column index  has the same probability weight.\n\nFields\n\ncardinality::Cardinality, the direction the compression matrix is intended to be   applied to a target matrix or operator. Values allowed are Left() or Right()    or Undef().\nreplace::Bool, if true, then the sampling occurs with replacement; if false,    then the sampling occurs without replacement.\n\nConstructor\n\nUniform(;cardinality=Undef(), replace = false)\n\nReturns\n\nA Uniform object.\n\n\n\n\n\n","category":"type"},{"location":"api/distributions/#RLinearAlgebra.UniformRecipe","page":"Distributions API","title":"RLinearAlgebra.UniformRecipe","text":"UniformRecipe <: DistributionRecipe\n\nThe recipe containing all allocations and information for the uniform distribution.\n\nFields\n\ncardinality::C where C<:Cardinality, the cardinality of the compressor. The   value is either Left() or Right() or Undef().\nreplace::Bool, an option to replace or not during the sampling process based    on the given weights.\nstate_space::Vector{Int64}, the row/column index set.\nweights::ProbabilityWeights, the weights of each element in the state space.\n\n\n\n\n\n","category":"type"},{"location":"api/distributions/#RLinearAlgebra.complete_distribution","page":"Distributions API","title":"RLinearAlgebra.complete_distribution","text":"complete_distribution(distribution::Distribution, A::AbstractMatrix)\n\nA function that generates a DistributionRecipe given the      arguments.\n\nArguments\n\ndistribution::Distribution, a user-specified distribution function for sampling.\nA::AbstractMatrix, a coefficient matrix. \n\nOutputs\n\nA DistributionRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#RLinearAlgebra.update_distribution!","page":"Distributions API","title":"RLinearAlgebra.update_distribution!","text":"update_distribution!(distribution::DistributionRecipe, A::AbstractMatrix)\n\nA function that updates the DistributionRecipe in place given      arguments.\n\nArguments\n\ndistribution::DistributionRecipe, a fully initialized realization of distribution.\nA::AbstractMatrix, a coefficient matrix. \n\nOutputs\n\nModifies the DistributionRecipe in place and returns nothing.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#RLinearAlgebra.sample_distribution!","page":"Distributions API","title":"RLinearAlgebra.sample_distribution!","text":"sample_distribution!(x::AbstractVector, distribution::DistributionRecipe)\n\nA function that in place updates the x by given DistributionRecipe info.\n\nArguments\n\nx::AbstractVector, an abstract vector to store the sampled indices. \ndistribution::DistributionRecipe, a fully initialized realization of distribution.\n\nOutputs\n\nModifies the x in place by sampling that follows the weights and replacement given by \n\n'DistributionRecipe'.\n\n\n\n\n\n","category":"function"},{"location":"manual/low_rank_approximators/#Low-Rank-Approximations-of-Matrices","page":"Low-Rank Approximation","title":"Low-Rank Approximations of Matrices","text":"Large matrices often contain redundant information. This means that it is  possible to form representations of large matrices with less data than what the  original matrix contains.  One way of representing a matrix with less data is through low-rank approximations.  Generally, low-rank approximations of a matrix A in mathbbR^m times n take two forms:  A approx MN  where M in mathbbR^m times r and N in mathbbR^r times n, or  A approx MBN where M in mathbbR^m times r, N in mathbbR^s times n, and  B in mathbbR^r times s. \n\nOnce one of the above representations has been obtained they can then be used  to speed up a number of computations including matrix multiplication, clustering, or approximate eigenvalue decompositions  [1–4].\n\nThe type of approximation depends on the symmetry of the matrix.  For symmetric matrices, we can use the Nystrom approximation. For non-symmetric matrices, we can use  the Generalized Nystrom decomposition or interpolative decompositions (IDs),  which select subsets of the rows and/or columns of a matrix. If these interpolative  decompositions are performed to select only columns or only  rows then they are known as one-sided IDs, if they are used  to select both columns and rows then they are known as a CUR decomposition. Below, we  present a summary of the decompositions in a table. \n\nApproximation Name Matrix Type Form of Approximation\nRandRangeFinder General A approx QQ^top A\nRandSVD General A approx U Sigma V^top\nNystrom Symmetric (AS)((SA)^top AS)^dagger(AS)^top\nGeneralized Nystrom General (AS_1)(S_2A AS_1)^dagger S_2 A\nCUR Yes Yes\nOne-Sided ID General AJU_c or U_r AI\n\nIn RLinearAlgebra,  once you have obtained a low-rank approximation Recipe, you can use it  to do multiplications (via mul!) and/or left inversion (via ldiv!).  Below we have the table of approximation recipes  and indicate how they can be used.\n\nApproximation Name mul! ldiv!\nRandRangeFinderRecipe Yes No\nRandSVDRecipe Yes No\nNystromRecipe Yes No\nCURRecipe Yes No\nIDRecipe (One-Sided ID) Yes No","category":"section"},{"location":"manual/low_rank_approximators/#The-Randomized-Rangefinder","page":"Low-Rank Approximation","title":"The Randomized Rangefinder","text":"The idea behind the randomized range finder is to find  an orthogonal matrix Q such that A approx QQ^top A. Halko et al. [1] showed that  forming Q was as simple as compressing A from the right   and storing the Q from the resulting QR factorization.  Despite the simplicity of this procedure,  if the compression dimension, k, exceeds 2, then A - QQ^top A_F leq sqrtk+1 (sum_i=k+1^min(mn)sigma_i)^12,  where sigma_k+1 is the k+1^textth singular value of A  [1, Theorem 10.5].  This is very close to the error from the truncated SVD, which  is known to be the lowest achievable error.  For matrices whose singular values decay quickly, this bound can be  conservative in comparison to observed performance.  However, for some matrices whose singular values  decay slowly this bound is fairly tight.  RLinearAlgebra implements the randomized rangefinder using  RangeFinder.\n\nPower iterations can be added to improve the quality of the approximation. Power iterations basically involve multiplying the matrix with itself,  which results in raising each singular value to a  higher power. This powering of the singular values increases the gap between the  singular values making them easier to resolve. In RLinearAlgebra, you can control the number of power iterations  using the power_its keyword in RangeFinder.\n\nOne issue with power iterations is that they can sometimes be  unstable.  We can improve the stability of these iterations by orthogonalizing between power iterations (akin to Arnoldi iterations). In RLinearAlgebra you can control whether or not the orthogonalization is performed using the orthogonalize keyword argument in the  RangeFinder. \n\ninfo: Info\nIf the cardinality of the compressor in the RangeFinder is not Right() a warning  will be returned and the approximation may be inefficient or less accurate.  ","category":"section"},{"location":"manual/low_rank_approximators/#A-RangeFinder-Example","page":"Low-Rank Approximation","title":"A RangeFinder Example","text":"Let's say that we wish to obtain a five-dimensional Randomized Rangefinder approximation  to matrix with 1000 rows and columns and a rank of five. In RLinearAlgebra, we can easily do this with the Fast Johnson-Lindenstrauss Compressor (see FJLT), say, as follows.\n\nusing RLinearAlgebra, LinearAlgebra\n\n# Generate the matrix we wish to approximate\nA = randn(1000, 5) * randn(5, 1000);\n\n# Form the RangeFinder Structure\napprox = RangeFinder(\n    compressor = FJLT(compression_dim = 5, cardinality = Right())\n)\n\n# Approximate A\nrange_A = rapproximate(approx, A)\n\n# Check the error of the approximation\nnorm(A - range_A * (range_A' * A))","category":"section"},{"location":"manual/low_rank_approximators/#Adding-Power-Iterations-with-and-without-Orthogonalization","page":"Low-Rank Approximation","title":"Adding Power Iterations with and without Orthogonalization","text":"To see the benefits of power iterations, consider the same example but now with  compression_dim = 3. \n\nBelow, we first compute the best possible truncation error using  a singular value decomposition of rank 3. Then, we compute the Randomized Rangefinder without the power iteration. Then, we compute the Randomized Rangefinder with the power iteration. Finally, we compute the Randomized Rangefinder with the power iteration and  orthogonalization.\n\n# Get error of truncated svd by computing the sqrt of the sum^2 of singular values 4:1000\nprintstyled(\"Error of rank 3 truncated SVD:\",\n    sqrt(sum(svd(A).S[4:end].^2)),\n    \"\\n\"\n)\n\n# Try approximating with a compression dimension of 3 and no power its/orthogonalization \n# Form the RangeFinder Structure\napprox = RangeFinder(\n    compressor = FJLT(compression_dim = 3, cardinality = Right())\n);\n\nrange_A = rapproximate(approx, A);\n\nprintstyled(\"Error of rank 3 approximation:\",\n    norm(A - range_A * (range_A' * A)),\n    \"\\n\"\n)\n\n# Now consider adding power iterations \napprox_pi = RangeFinder(\n    compressor = FJLT(compression_dim = 3, cardinality = Right()),\n    power_its = 10\n);\n\nrange_A_pi = rapproximate(approx_pi, A);\n\n\nprintstyled(\"Error with 10 Power its and Orthogonalization:\",\n    norm(A - range_A_pi * (range_A_pi' * A)),\n    \"\\n\"\n)\n\n# Now consider power its with orthogonalization\napprox_pi_o = RangeFinder(\n    compressor = FJLT(compression_dim = 3, cardinality = Right()),\n    power_its = 10,\n    orthogonalize = true\n);\n\nrange_A_pi_o = rapproximate(approx_pi_o, A);\n\nprintstyled(\"Error with 10 Power its and Orthogonalization:\",\n    norm(A - range_A_pi_o * (range_A_pi_o' * A)),\n    \"\\n\"\n)","category":"section"},{"location":"manual/low_rank_approximators/#The-RandSVD","page":"Low-Rank Approximation","title":"The RandSVD","text":"The RandomizedSVD is a form of low-rank approximation that returns the approximate  singular values and vectors of the truncated SVD. Algorithmically, it is implemented as three additional steps to the Randomized Rangefinder in [1].  Specifically these steps are:\n\nTake the Q matrix from the Randomized Rangefinder and compute Q^top A.  \nCompute the WSV = textsvd(Q^top A).\nObtain the left singular vectors from U = Q^top W.\n\nSince, the RandomizedSVD is simply an extension of the Randomized RangeFinder, the effects of all modifications, such as power iterations and orthogonalization still apply.  The  difference between the two procedures is found in the Recipes. Where for the RandSVDRecipe you find a approximate truncated SVD where the singular values can be accessed by  calling recipe.S, the left singular vectors can be accessed by calling recipe.U, and the right singular vectors can be accessed by calling recipe.V. Additionally,  when you multiply with the RandomizedSVD it is as if you are multiplying with the  truncated SVD, meaning for a vector x the operation USV^top x is performed. This  type of multiplication can be substantially faster than multiplications with the original  matrix.\n\ninfo: Info\nAs for the RandomizedSVD if the cardinality of the compressor is not Right() a warning  will be returned and the approximation may be incorrect.","category":"section"},{"location":"manual/low_rank_approximators/#A-RandSVD-example","page":"Low-Rank Approximation","title":"A RandSVD example","text":"We now demonstrate how to use the RandSVD, by first generating the technique structure  with a FJLT compressor with compression_dim = 5 and cardinality = Right(). Then we  will run rapproximate and compare the singular values of the returned recipe to the  5 singular values of the truncated SVD. We will then end the experiment by comparing  the difference between multiplying a our RandSVDRecipe to vector and multiplying the  original matrix.\n\nusing RLinearAlgebra, LinearAlgebra\n\n# Generate the matrix we wish to approximate\nA = randn(1000, 5) * randn(5, 1000);\n\n# Form the RangeFinder Structure\napprox = RandSVD(\n    compressor = FJLT(compression_dim = 5, cardinality = Right())\n)\n\n# Approximate A\nrandsvd_A = rapproximate(approx, A)\n\n# Compare singular vectors\nsvd(A).S[1:5]\n\nrandsvd_A.S\n\n# Compare multiplications\nx = rand(1000);\n\nnorm(A * x - randsvd_A * x)\n\ninfo: Info\nAs for the RandomizedSVD if the cardinality of the compressor is not Right() a warning will be returned and the approximation may be incorrect.","category":"section"},{"location":"api/approximators/#Approximators","page":"Approximators API","title":"Approximators","text":"Pages = [\"approximators.md\"]","category":"section"},{"location":"api/approximators/#Abstract-Types","page":"Approximators API","title":"Abstract Types","text":"","category":"section"},{"location":"api/approximators/#Range-Approximator-Structures","page":"Approximators API","title":"Range Approximator Structures","text":"","category":"section"},{"location":"api/approximators/#General-Oblique-Approximators","page":"Approximators API","title":"General Oblique Approximators","text":"","category":"section"},{"location":"api/approximators/#CURCore-Structures","page":"Approximators API","title":"CURCore Structures","text":"","category":"section"},{"location":"api/approximators/#Exported-Functions","page":"Approximators API","title":"Exported Functions","text":"","category":"section"},{"location":"api/approximators/#Internal-Functions","page":"Approximators API","title":"Internal Functions","text":"","category":"section"},{"location":"api/approximators/#RLinearAlgebra.Approximator","page":"Approximators API","title":"RLinearAlgebra.Approximator","text":"Approximator\n\nAn abstract supertype for structures that store user-controlled parameters corresponding to techniques that form low-rank approximations of the matrix A.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.ApproximatorRecipe","page":"Approximators API","title":"RLinearAlgebra.ApproximatorRecipe","text":"ApproximatorRecipe\n\nAn abstract supertype for structures that store user-controlled parameters, linear system dependent parameters and preallocated memory corresponding to techniques that form low-rank approximations of the matrix A.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.ApproximatorAdjoint","page":"Approximators API","title":"RLinearAlgebra.ApproximatorAdjoint","text":"ApproximatorAdjoint{S<:ApproximatorRecipe} <: ApproximatorRecipe\n\nA structure for the adjoint of an ApproximatorRecipe.\n\nFields\n\nParent::ApproximatorRecipe, the approximator that we compute the adjoint of.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.RangeApproximator","page":"Approximators API","title":"RLinearAlgebra.RangeApproximator","text":"RangeApproximator\n\nAn abstract type for the structures that contain the user-controlled parameters  corresponding to the Approximator methods that produce an orthogonal approximation to the  range of a matrix A. This includes methods like the RandomizedSVD and  randomized rangefinder.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.RangeApproximatorRecipe","page":"Approximators API","title":"RLinearAlgebra.RangeApproximatorRecipe","text":"RangeApproximatorRecipe\n\nAn abstract type for the structures that contain the user-controlled parameters,  linear system information, and preallocated memory for methods corresponding to the Approximator methods that produce an orthogonal approximation to the range of a matrix A. This includes methods like the RandomizedSVD and  randomized rangefinder.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.CURCore","page":"Approximators API","title":"RLinearAlgebra.CURCore","text":"CURCore\n\nAn abstract type for computing the core linking matrix in a CUR decomposition.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.CURCoreRecipe","page":"Approximators API","title":"RLinearAlgebra.CURCoreRecipe","text":"CURCoreRecipe\n\nAn abstract type for the recipes containing the preallocated information required for     computing the core linking matrix in a CUR decomposition.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.CURCoreAdjoint","page":"Approximators API","title":"RLinearAlgebra.CURCoreAdjoint","text":"CURCoreAdjoint{S<:CURCoreRecipe} <: CURCoreRecipe\n\nA structure for the adjoint of an CURCoreRecipe.\n\nFields\n\nParent::CURCoreRecipe, the approximator that we are taking the adjoint.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.RandSVD","page":"Approximators API","title":"RLinearAlgebra.RandSVD","text":"RandSVD\n\nA struct that implements the Randomized SVD. The Randomized SVD technique compresses a      matrix from the right to compute a rank k estimate to the truncated      SVD of a matrix A. See Algorithm 5.1 in [1] for additional      details.\n\nMathematical Description\n\nSuppose we have a matrix A in mathbbR^m times n for which we wish to form a      low-rank approximation with the form of an SVD. Specifically, we wish to find an      orthogonal matrix, U, a diagonal matrix, Sigma, and an orthogonal matrix,      V such that USigma V^top approx A. This can be done effectively using the      Randomized SVD presented in Algorithm 5.1 of [1].      This algorithm progresses by first having the user select a k  2 to be the      compression_dim of the compressor, which will also correspond to the desired      rank of the approximation. With this k, RandomizedSVD  generates a compression      matrix SinmathbbR^n times k and computes Q = textqr(AS) as in the      RangeFinder. With the Q, the RandomizedSVD      concludes by computing WSigmaV = textSVD(Q^top A) and  setting U = QW.     With high probability the approximation generated by the RandomizedSVD will satisfy      mathbbE A - U Sigma V^top _F leq sqrtk+1       (sum_i=k+1^min(mn)sigma_i)^12     , where sigma_k+1 is the k+1^textth singular value of (see Theorem 10.5      of [1]). This bound is often conservative as long as the singular      values of A decay quickly.\n\nWhen the singular values decay slowly, we can improve the quality of the approximation using the      power iteration, which applies A and A^top, q times      and take the qr factorization of (AA^top)^q AS. Using these power iterations      increases the relative gap between the singular values leading to  better RandomizedSVD      performance. \n\nPerforming power iterations in floating points can destroy all information      related to the smallest singular values of A      (see Remark 4.3 in [1]). We can preserve this information by      orthogonalizing inbetween the products of AS with A or A^top      in the power iteration. These steps are known as the orthogonalized power      iteration (see Algorithm 4.4 of [1]).       Orthogonalized power iterations progress according to the following steps:\n\ntildeA_1 = AS  \nQ_1R_1 = textbfqr(tildeA_1)  \ntildeA_2 = A^top Q_1  \nQ_2R_2 = textbfqr(tildeA_2)  \ntildeA_1 = A Q_2  \nQ_1 R_1 = textbfqr(tildeA_1)  \nRepeat Steps 3 through 6 for the desired number of power iterations  set Q = Q_1.  \n\nFields\n\ncompressor::Compressor, the technique for compressing the matrix from the right.\npower_its::Int64, the number of power iterations that should be performed.\northogonalize::Bool, a boolean indicating whether the power_its should be performed    with orthogonalization.    \nblock_size::Int64, the size of the tile when performing matrix multiplication. By    default, block_size = 0, this will be set to be the number of columns in    the original matrix, A.\n\nConstructor\n\nRandSVD(;\n    compressor::Compressor = SparseSign(cardinality = Right()), \n    orthogonalize::Bool  = false, \n    power_its::Int64 = 0,\n    block_size::Int64 = 0,\n)\n\nKeywords\n\ncompressor::Compressor, the technique for compressing the matrix from the right. By    default this is SparseSign with a cardinality Right().\npower_its::Int64, the number of power iterations that should be performed. By default    this is zero.\northogonalize::Bool, a boolean indicating whether the power_its should be performed   with orthogonalization. By default is false. \nblock_size::Int64, the size of the tile when performing matrix multiplication. By    default, block_size = 0, this will be set to be the number of columns in    the original matrix, A. By default this is zero.\n\nReturns\n\nA RandSVD object.\n\nThrows\n\nArgumentError if power_its or block_size are negative.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.RandSVDRecipe","page":"Approximators API","title":"RLinearAlgebra.RandSVDRecipe","text":"RandSVDRecipe\n\nA struct that contains the preallocated memory and completed compressor to form a     RandSVD approximation to the matrix A.\n\nFields\n\nn_rows::Int64, the number of rows in the approximation. \nn_cols::Int64, the number of columns in the approximation. \ncompressor::CompressorRecipe, the compressor to be applied from the right to A.\npower_its::Int64, the number of power iterations that should be performed.\northogonalize::Bool, a boolean indicating whether the power_its should be performed    with orthogonalization.\nU::AbstractArray, the orthogonal matrix that approximates the top compressor_dim    left singular vectors of A.\nS::AbstractVector, a vector containing the top compressor_dim singular values of    A.\nV::AbstractArray, the orthogonal matrix that approximates the top compressor_dim    right singular vectors of A.\nbuffer::AbstractArray, the storage for matrix multiplication with this low-rank    approximation. Will have the compression_dim number of rows and block_size   number of columns.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.RangeFinder","page":"Approximators API","title":"RLinearAlgebra.RangeFinder","text":"RangeFinder\n\nA struct that implements the Randomized Range Finder technique which uses compression from      the right to form an low-dimensional orthogonal matrix Q that approximates the      range of A. See [1] for additional details.\n\nMathematical Description\n\nSuppose we have a matrix A in mathbbR^m times n of which we wish to form a low      rank approximation that approximately captures the range of A. Specifically, we wish     to find an Orthogonal matrix Q such that QQ^top A approx A. \n\nA simple way to find such a matrix is to choose a k representing the number of      vectors we wish to have in the subspace. Then we can generate a compression matrix      SinmathbbR^n times k and compute Q = textqr(AS).      With high probability we will have A - QQ^top A_F leq     sqrtk+1 (sum_i=k+1^min(mn)sigma_i)^12,      where sigma_k+1 is the k+1^textth singular value      of A (see Theorem 10.5 of [1]). This bound is often conservative      as long as the singular values of A decay quickly.  \n\nWhen the singular values decay slowly, we can improve the quality of the approximation using the      power iteration, which applies A and A^top, q times      and take the qr factorization of (AA^top)^q AS. Using these power iterations increases the      relative gap between the singular values leading to  better Rangefinder performance. \n\nPerforming power iterations in floating points can destroy all information      related to the smallest singular values of A      (see Remark 4.3 in [1]). We can preserve this information by      orthogonalizing inbetween the products of AS with A or A^top      in the power iteration. These steps are known as the orthogonalized power      iteration (see Algorithm 4.4 of [1]).       Orthogonalized power iterations progress according to the following steps:\n\ntildeA_1 = AS  \nQ_1R_1 = textbfqr(tildeA_1)  \ntildeA_2 = A^top Q_1  \nQ_2R_2 = textbfqr(tildeA_2)  \ntildeA_1 = A Q_2  \nQ_1 R_1 = textbfqr(tildeA_1)  \nRepeat Steps 3 through 6 for the desired number of power iterations  set Q = Q_1. \n\nFields\n\ncompressor::Compressor, the technique that will compress the matrix from the right.\npower_its::Int64, the number of power iterations that should be performed.\northogonalize::Bool, a boolean indicating whether the power_its should be performed    with orthogonalization.\n\nConstructor\n\nRangeFinder(;\n    compressor = SparseSign(), \n    orthogonalize = false, \n    power_its = 0\n)\n\nKeywords\n\ncompressor::Compressor, the technique that will compress the matrix from the right.\npower_its::Int64, the number of power iterations that should be performed. Default is   zero.\northogonalize::Bool, a boolean indicating whether the power_its should be performed    with orthogonalization. Default is false.\n\nReturns\n\nA RangeFinder object.\n\nThrows\n\nArgumentError if power_its is negative.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.RangeFinderRecipe","page":"Approximators API","title":"RLinearAlgebra.RangeFinderRecipe","text":"RangeFinderRecipe\n\nA struct that contains the preallocated memory and completed compressor to form a     RangeFinder approximation to the matrix A.\n\nFields\n\ncompressor::CompressorRecipe, the compressor to be applied from the right to A.\npower_its::Int64, the number of power iterations that should be performed.\northogonalize::Bool, a boolean indicating whether the power_its should be performed    with orthogonalization.\nrange::AbstractMatrix, the orthogonal matrix that approximates the range of A.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.CUR","page":"Approximators API","title":"RLinearAlgebra.CUR","text":"CUR <: Approximator\n\nA struct that implements the CUR decomposition, a technique for computing a      low-rank approximation to a matrix, A. This technique selects column subsets,      C, row subsets, R, and a linking matrix, U      (this can either be C^dagger A R^dagger or AIJ,      where I is a set of row indices and J is a set of column indices) such that      A approx CUR\n\nMathematical Description\n\nIn general finding a I and J that minimize the approximation error is a     NP-hard problem (you're not going to do it)[14];      thus, we often aim to find sufficiently      good indices. The best known quality of a rank r cur approximation to a  matrix     tilde A_r is known to be      A - tilde A_r _F leq (r + 1) A - A_r_F     where A_r is the rank-r truncated svd [15].\n\nIn practice numerous randomized methods match the performance of this best possible      selection procedure. These approaches can be broken into sampling and pivoting      approaches. The sampling approaches, like leverage score sampling      [16], typically have better theory, and involve      imputing a distribution over the rows/columns of a matrix     and drawing from that distribution with replacement. Randomized pivoting procedures     on the other hand tend to be more efficient and accurate in practice and involve      compressing the matrix then applying a pivoting procedure on the compressed form     [17].\n\nFields\n\nrank::Int64, the desired rank of approximation.\noversample::Int64, the amount of extra indices we wish to select with the row selection   procedure. By default this is zero, although it can improve the stability of the    approximation [18].\ncol_selector::Selector, the technique used for selecting column indices from a matrix.\nrow_selector::Selector, the technique used for selecting row indices from a matrix.\ncore::Core, the method for computing the core linking matrix, U, in the CUR.\nblock_size::Int64, number of vectors stored in a buffer matrix for multiplication.\n\nConstructor\n\nCUR(rank;\n    oversample = 0,\n    selector_cols = LUPP(),\n    selector_rows = selector_cols,\n    core = CrossApproximation(),\n)\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.CURRecipe","page":"Approximators API","title":"RLinearAlgebra.CURRecipe","text":"CURRecipe <: ApproximatorRecipe\n\nA struct that contains the preallocated memory and completed Selectors to form a     CUR approximation to the matrix A.\n\nFields\n\nn_rows::Int64, the row dimension of the approximation. \nn_cols::Int64, the column dimension of the approximation. \nn_row_vecs::Int64, the number of rows selected in the approximation. \nn_col_vecs::Int64, the number of columns selected in the approximation.\ncol_selector::SelectorRecipe, the method for selecting columns.\nrow_selector::SelectorRecipe, the method for selecting rows.\nrow_idx::Vector{Int64}, the selected row indices.\ncol_idx::Vector{Int64}, the selected column indices.\nC::AbstractMatrix, the entries of A at the selected column indices.\nU::CURCoreRecipe, the matrix linking the C and R matrices to approximate A.\nR::AbstractMatrix, the entries of A at the selected row indices.\nbuffer_row::AbstractArray, a buffer matrix used to store the result of R    multiplied with an array.\nbuffer_core::AbstractArray, a buffer matrix used to store the result of U    multiplied with an array.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.CrossApproximation","page":"Approximators API","title":"RLinearAlgebra.CrossApproximation","text":"CrossApproximation <: CURCore\n\nA form of the core matrix in CUR decomposition, such that for column indices, J, and row indices, I, the matrix U is AIJ^dagger.\n\nFields\n\nNone\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.CrossApproximationRecipe","page":"Approximators API","title":"RLinearAlgebra.CrossApproximationRecipe","text":"CrossApproximationRecipe <: CURCore\n\nA structure featuring the preallocated arrays necessary for storing the cross-approximation core matrix to a CUR decomposition.\n\nFields\n\nn_rows::Int64, the number of rows in the core matrix.\nn_cols::Int64, the number of columns in the core matrix.\ncore::AbstractMatrix, the core matrix, found as the intersection of the row and column   indices.\n\n\n\n\n\n","category":"type"},{"location":"api/approximators/#RLinearAlgebra.complete_approximator","page":"Approximators API","title":"RLinearAlgebra.complete_approximator","text":"complete_approximator(approximator::Approximator, A::AbstractMatrix)\n\nA function that generates an ApproximatorRecipe given      arguments.\n\nArguments\n\napproximator::Approximator, a data structure containing the   user-defined parameters associated with a particular low-rank approximation.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nAn ApproximatorRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/approximators/#RLinearAlgebra.complete_core","page":"Approximators API","title":"RLinearAlgebra.complete_core","text":"complete_core()\n\nA function that generates a CURCoreRecipe given the arguments.\n\nArguments\n\ningredients::CURCore, a data structure containing the user-defined parameters    associated with a particular type of core matrix in a CUR decomposition.\ncur::CUR, a data structure containing the user-defined parameters for the CUR    approximation.\nA::AbstractMatrix, a target matrix for approximation.\n\n\n\n\n\n","category":"function"},{"location":"api/approximators/#RLinearAlgebra.update_core!","page":"Approximators API","title":"RLinearAlgebra.update_core!","text":"update_core!()\n\nA function that updates the CURCoreRecipe based on the parameters defined in the CUR     structure.\n\nArguments\n\ncore::CURCoreRecipe, a data structure containing the preallocated data structures    necessary for computing the core matrix in a CUR decomposition.\ncur::CURRecipe, a data structure containing the user-defined parameters and    preallocated structures.\nA::AbstractMatrix, a target matrix to be approximated.\n\n\n\n\n\n","category":"function"},{"location":"api/approximators/#RLinearAlgebra.rapproximate","page":"Approximators API","title":"RLinearAlgebra.rapproximate","text":"rapproximate(approximator::Approximator, A::AbstractMatrix)\n\nA function that computes a low-rank approximation of the matrix A     using the information in the provided Approximator data structure.\n\nArguments\n\napproximator::Approximator, a data structure containing the   user-defined parameters associated with a particular low-rank approximation.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nAn ApproximatorRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/approximators/#RLinearAlgebra.rapproximate!","page":"Approximators API","title":"RLinearAlgebra.rapproximate!","text":"rapproximate!(approximator::ApproximatorRecipe, A::AbstractMatrix)\n\nA function that computes a low-rank approximation of the matrix A     using the information in the provided Approximator data structure.\n\nArguments\n\napproximator::ApproximatorRecipe, a fully initialized   realization for a low rank approximation method for a particular matrix.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nAn ApproximatorRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/approximators/#RLinearAlgebra.rand_power_it","page":"Approximators API","title":"RLinearAlgebra.rand_power_it","text":"rand_power_it(approx::RangeFinderRecipe, A::AbstractMatrix)\n\nFunction that performs the randomized rangefinder procedure presented in Algortihm 4.3 of  [1].\n\nArguments\n\napprox::RangeFinderRecipe, a RangeFinderRecipe structure that contains the compressor\n\nrecipe.\n\nA::AbstractMatrix, the matrix being approximated.\n\nReturns\n\nQ::AbstractMatrix, an economical Q approximating the range of A.\n\n\n\n\n\n","category":"function"},{"location":"api/approximators/#RLinearAlgebra.rand_ortho_it","page":"Approximators API","title":"RLinearAlgebra.rand_ortho_it","text":"rand_ortho_it(approx::RangeFinderRecipe, A::AbstractMatrix)\n\nFunction that performs the randomized rangefinder procedure presented in Algortihm 4.4 of  [1].\n\nArguments\n\napprox::RangeFinderRecipe, a RangeFinderRecipe structure that contains the compressor\n\nrecipe.\n\nA::AbstractMatrix, the matrix being approximated.\n\nReturns\n\nQ::AbstractMatrix, an economical Q approximating the range of A.\n\n\n\n\n\n","category":"function"},{"location":"api/solver_errors/#SolverErrors","page":"SolverErrors API","title":"SolverErrors","text":"Pages = [\"solver_errors.md\"]","category":"section"},{"location":"api/solver_errors/#Abstract-Types","page":"SolverErrors API","title":"Abstract Types","text":"","category":"section"},{"location":"api/solver_errors/#SolverError-Structures","page":"SolverErrors API","title":"SolverError Structures","text":"","category":"section"},{"location":"api/solver_errors/#Exported-Functions","page":"SolverErrors API","title":"Exported Functions","text":"","category":"section"},{"location":"api/solver_errors/#RLinearAlgebra.SolverError","page":"SolverErrors API","title":"RLinearAlgebra.SolverError","text":"SolverError\n\nAn abstract supertype for structures that track and/or evaluate the quality of a solution for a linear system or least squares.\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.SolverErrorRecipe","page":"SolverErrors API","title":"RLinearAlgebra.SolverErrorRecipe","text":"SolverErrorRecipe\n\nAn abstract supertype for structures that contain the user-controlled parameters, linear system dependent parameters, and preallocated memory for techniques that evaluate the solution to a linear solver.\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.FullResidual","page":"SolverErrors API","title":"RLinearAlgebra.FullResidual","text":"FullResidual <: SolverError\n\nA SolverError structure for computing the norm of the full residual, b-Ax.\n\nFields\n\nNone\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.FullResidualRecipe","page":"SolverErrors API","title":"RLinearAlgebra.FullResidualRecipe","text":"FullResidual <: SolverErrorRecipe\n\nA SolverErrorResidual structure for computing the norm of the full residual, b-Ax\n\nFields\n\nresidual::AbstractVector, a container for the residual b-Ax.\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.LSGradient","page":"SolverErrors API","title":"RLinearAlgebra.LSGradient","text":"LSGradient <: SolverError\n\nA SolverError structure for monitoring the residual of the normal equations      of a linear system (equivalently, the gradient of the least squares problem),     -A^top (b - Ax).\n\nFields\n\nNone\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.LSGradientRecipe","page":"SolverErrors API","title":"RLinearAlgebra.LSGradientRecipe","text":"LSGradientRecipe <: SolverErrorRecipe\n\nA SolverErrorRecipe structure for storing the residual of the normal equations      of a linear system (equivalently, the gradeint of the least squares problem),     -A^intercal (b - Ax).\n\nFields\n\ngradient::AbstractVector, -A^top (b - Ax).\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.CompressedResidual","page":"SolverErrors API","title":"RLinearAlgebra.CompressedResidual","text":"CompressedResidual <: ErrorRecipe\n\nA structure for the compressed residual, Sb-SAx.\n\nFields\n\nNone\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.CompressedResidualRecipe","page":"SolverErrors API","title":"RLinearAlgebra.CompressedResidualRecipe","text":"CompressedResidualRecipe <: ErrorRecipe\n\nA structure containing the preallocated structures for the compressed residual, Sb-SAx.\n\nFields\n\nresidual::AbstractVector, a container for the compressed residual, Sb-SAx.\nresidual_view::SubArray, a view of the residual container to handle varying compression   sizes.\n\n\n\n\n\n","category":"type"},{"location":"api/solver_errors/#RLinearAlgebra.complete_error","page":"SolverErrors API","title":"RLinearAlgebra.complete_error","text":"complete_error(\n    error::SolverError, \n    solver::Solver,\n    A::AbstractMatrix, \n    b::AbstractVector\n)\n\nA function that generates a SolverErrorRecipe given the      arguments.\n\nArguments\n\nerror::SolverError, a user-specified solver error method.\nsolver::Solver, a user-specified solver method.\nA::AbstractMatrix, a coefficient matrix. \nb::AbstractVector, a constant vector. \n\nReturns\n\nA SolverErrorRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/solver_errors/#RLinearAlgebra.compute_error","page":"SolverErrors API","title":"RLinearAlgebra.compute_error","text":"compute_error(\n    error::SolverErrorRecipe, \n    solver::SolverRecipe, \n    x::AbstractVector,\n    A::AbstractMatrix, \n    b::AbstractVector\n)\n\nA function that evaluates the error for a proposed solution      vector.\n\nArguments\n\nerror::SolverErrorRecipe, a fully initialized realization for   a solver error method for a specific linear system or least squares problem.\nsolver::SolverRecipe, a fully initialized realization for a    solver method for a specific linear system.\nx::AbstractVector, a vector for the proposed solution. \nA::AbstractMatrix, a coefficient matrix. \nb::AbstractVector, a constant vector. \n\nReturns\n\nReturns nothing\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#Solvers-API","page":"Solvers API","title":"Solvers API","text":"Pages = [\"solvers.md\"]","category":"section"},{"location":"api/solvers/#Abstract-Types","page":"Solvers API","title":"Abstract Types","text":"","category":"section"},{"location":"api/solvers/#Solver-Structures","page":"Solvers API","title":"Solver Structures","text":"","category":"section"},{"location":"api/solvers/#Exported-Functions","page":"Solvers API","title":"Exported Functions","text":"","category":"section"},{"location":"api/solvers/#Internal-Functions","page":"Solvers API","title":"Internal Functions","text":"","category":"section"},{"location":"api/solvers/#RLinearAlgebra.Solver","page":"Solvers API","title":"RLinearAlgebra.Solver","text":"Solver\n\nAn abstract supertype for structures that contain the user-controlled parameters for methods that solve linear systems and least squares problems.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.SolverRecipe","page":"Solvers API","title":"RLinearAlgebra.SolverRecipe","text":"SolverRecipe\n\nAn abstract supertype specifying a solver method with pre-allocated data structures given a coefficient matrix and constant vector.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.ColumnProjection","page":"Solvers API","title":"RLinearAlgebra.ColumnProjection","text":"ColumnProjection <: Solver\n\nA specification of a column projection solver, which is a generalization of      (block) coordinate descent for least squares problems.      These solvers iteratively update a solution by projecting the solution      onto a compressed column space of the coefficient matrix. \n\nMathematical Description\n\nLet A be an m times n matrix and consider solving the linear least squares problem min_x Vert b - Ax Vert_2 Column projection methods refine a current iterate x by the update      x_+ = x + Sv where S is a compression and v is the minimum two-norm solution  to  min_w Vert b - A(x + Sw) Vert_2\n\nExplicitly, the solution is  v = (S^top A^top A S)^dagger (AS)^top (b - Ax)     = (S^top A^top)^dagger (b - A x) which yields      x_+ = x + S (S^top A^top)^dagger (b - Ax)\n\nHere, we allow for an additional relaxation parameter, alpha, which  results in the update  x_+ = x + alpha S (S^top A^top)^dagger (b - Ax)\n\nWhen the compression S is a vector, the update simplifies to  x_+ = x + alpha S frac (AS)^top (b - Ax) Vert AS Vert^2 Letting r = b - Ax, the residual r_+ = b - Ax_+ can be computed  by   r_+ = r - alpha (AS) v\n\nFields\n\nalpha::Float64, the over-relaxation parameter. \ncompressor::Compressor, a technique for forming the compressed column space of the    linear system.\nlog::Logger, a technique for logging the progress of the solver.\nerror::SolverError, a method for estimating the progress of the solver.\nsub_solver::SubSolver, a technique to perform the projection of the solution onto the    compressed column space.\n\nConstructor\n\nColumnProjection(;\n    alpha::Float64 = 1.0,\n    compressor::Compressor = SparseSign(cardinality=Right()), \n    error::SolverError = LSGradient(),\n    log::Logger = BasicLogger(),\n    sub_solver::SubSolver = QRSolver(), \n)\n\nKeywords\n\nalpha::Float64, the over-relaxation parameter. By default this value is 1.\ncompressor::Compressor, a technique for forming the compressed column space of the    linear system. By default it is a SparseSign compressor.\nerror::SolverError, a method for estimating the progress of the solver. By default it is    the LSGradient error method.\nlog::Logger, a technique for logging the progress of the solver. By default it is   BasicLogger.\nsub_solver::SubSolver, a technique to perform the projection of the solution onto the    compressed rowspace. When the compression_dim = 1 this is not used. For all other    cases, the default is QRSolver.\n\nReturns\n\nA ColumnProjection object.\n\ninfo: Info\nThe alpha parameter should be in (02) for convergence to be guaranteed.  This condition is not enforced in the constructor. There are instances where  setting alpha=2 can lead to non-convergent cycles [10].\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.ColumnProjectionRecipe","page":"Solvers API","title":"RLinearAlgebra.ColumnProjectionRecipe","text":"ColumnProjectionRecipe{\n    T<:Number, \n    V<:AbstractVector,\n    M<:AbstractArray, \n    MV<:SubArray,\n    C<:CompressorRecipe, \n    L<:LoggerRecipe,\n    E<:SolverErrorRecipe, \n    B<:SubSolverRecipe\n} <: SolverRecipe\n\nA mutable structure containing all information relevant to the ColumnProjection solver. It      is formed by calling the function complete_solver on a ColumnProjection      object.\n\nFields\n\ncompressor::CompressorRecipe, a technique for forming the compressed column space of the    linear system.\nlog::LoggerRecipe, a technique for logging the progress of the solver.\nerror::SolverErrorRecipe, a method for estimating the progress of the solver.\nsub_solver::SubSolverRecipe, a technique to perform the projection of the solution    onto the compressed column space.\nalpha::Float64, the over-relaxation parameter. It is multiplied by the update and can    affect convergence.\ncompressed_mat::AbstractMatrix, a matrix container for storing the compressed matrix.    Will be set to be the largest possible block size.\nsolution_vec::AbstractVector, a vector container for storing the current solution    to the linear system.\nupdate_vec::AbstractVector, a vector container for storing the update to the solution.\nmat_view::SubArray, a container for storing a view of the compressed matrix container.    Using views here allows for variable block sizes.\nresidual_vec::AbstractVector, a vector container for storing the residual at each    iteration.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.IHS","page":"Solvers API","title":"RLinearAlgebra.IHS","text":"IHS <: Solver\n\nAn implementation of the Iterative Hessian Sketch solver for solving over determined  least squares problems [11].\n\nMathematical Description\n\nLet A  in mathbbR^m times n m gg n and consider the least square problem  min_x Ax - b _2^2. If we let S in mathbbR^s times m be a  compression matrix, then Iterative Hessian Sketch iteratively finds a solution to this  problem by repeatedly updating x_k+1 = x_k + alpha u_kwhere u_k is the solution  to the convex optimization problem,  u_k in argmin_u S_k Au_2^2 - langle A b - Ax_k rangle  This method  has been to shown to converge geometrically at a rate rho in (0 12. Typically the  required compression dimension needs to be 4-8 times the size of n for the algorithm to  perform successfully.\n\nFields\n\nalpha::Float64, a step size parameter.\ncompressor::Compressor, a technique for forming the compressed linear system.\nlog::Logger, a technique for logging the progress of the solver.\nerror::SolverError, a method for estimating the progress of the solver.\n\nConstructor\n\nfunction IHS(;\n    compressor::Compressor = SparseSign(cardinality = Left()),\n    log::Logger = BasicLogger(),\n    error::SolverError = FullResidual(),\n    alpha::Float64 = 1.0\n)\n\nKeywords\n\ncompressor::Compressor, a technique for forming the compressed linear system.\nlog::Logger, a technique for logging the progress of the solver.\nerror::SolverError, a method for estimating the progress of the solver.\nalpha::Float64, a step size parameter.\n\nReturns\n\nA IHS object.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.IHSRecipe","page":"Solvers API","title":"RLinearAlgebra.IHSRecipe","text":"IHSRecipe{\n    Type<:Number, \n    LR<:LoggerRecipe,\n    CR<:CompressorRecipe,\n    ER<:ErrorRecipe,\n    M<:AbstractArray, \n    MV<:SubArray, \n    V<:AbstractVector\n} <: SolverRecipe\n\nA mutable structure containing all information relevant to the Iterative Hessian Sketch  solver. It is formed by calling the function complete_solver on a IHS solver, which  includes all the user controlled parameters, the linear system A, and the constant  vector b.\n\nFields\n\nlog::LoggerRecipe, a technique for logging the progress of the solver.\ncompressor::CompressorRecipe, a technique for compressing the matrix A.\nerror::SolverErrorRecipe, a technique for estimating the progress of the solver.\nalpha::Float64, a step size parameter, by default is set to 1.\ncompressed_mat::AbstractMatrix, a buffer for storing the compressed matrix.\nmat_view::SubArray, a container for storing a view of the compressed matrix buffer.\nresidual_vec::AbstractVector, a vector that contains the residual of the linear system    Ax-b.\ngradient_vec::AbstractVector, a vector that contains the gradient of the least squares    problem, A^top(b-Ax).\nbuffer_vec::AbstractVector, a buffer vector for storing intermediate linear system solves.\nsolution_vec::AbstractVector, a vector storing the current IHS solution.\nR::UpperTriangular, a container for storing the upper triangular portion of the R    factor from a QR factorization of mat_view. This is used to solve the IHS sub-problem.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.Kaczmarz","page":"Solvers API","title":"RLinearAlgebra.Kaczmarz","text":"Kaczmarz <: Solver\n\nAn implementation of a Kaczmarz solver. Specifically, it is a solver that iteratively     updates an iterate by projecting the iterate onto (a subspace of) the row space of a     consistent linear system.\n\nMathematical Description\n\nLet A be an m times n matrix and consider the consistent linear system Ax=b.      We can view the solution to this linear system as lying at the intersection of the      row hyperplanes,      cap_i in 1 ldots mu in mathbbR^n  A_i cdot u = b_i     ,     where A_i cdot represents the i^textth row of A. One way to find      this interesection is to iteratively project some abritrary point, x from one      hyperplane to the next, through      x_+ = x + alpha fracb_i -  A_icdot^top x A_icdot _2^2      Doing this with random permutation of i can lead to a geometric convergence      [12].     Here alpha is viewed as an over-relaxation parameter and can improve convergence.      One can also generalize this procedure to blocks by considering the S being a      s times n random matrix. If we let tilde A = S A and tilde b = Sb      then we can perform block kaczmarz as described by [13] with      x_+ = x + alpha tilde A^top (tilde A tilde A^top)^dagger      (tilde b - tilde A x)     While, S is often random, in reality, whether S is deterministic or random is      quite flexible see [6] for more details.\n\nFields\n\nalpha::Float64, the over-relaxation parameter. It is multiplied by the update and can    affect convergence.\ncompressor::Compressor, a technique for forming the compressed rowspace of the linear    system.\nlog::Logger, a technique for logging the progress of the solver.\nerror::SolverError, a method for estimating the progress of the solver.\nsub_solver::SubSolver, a technique to perform the projection of the solution onto the    compressed rowspace.\n\nConstructor\n\nKaczmarz(;\n    compressor::Compressor = SparseSign(), \n    log::Logger = BasicLogger(),\n    error::SolverError = FullResidual(),\n    sub_solver::SubSolver = LQSolver(),\n    alpha::Float64 = 1.0\n)\n\nKeywords\n\ncompressor::Compressor, a technique for forming the compressed rowspace of the    linear system.\nlog::Logger, a technique for logging the progress of the solver.\nerror::SolverError, a method for estimating the progress of the solver.\nsub_solver::SubSolver, a technique to perform the projection of the solution onto the    compressed rowspace. When the compression_dim = 1 this is not used.\nalpha::Float64, the over-relaxation parameter. It is multiplied by the update and can    affect convergence. By default this value is 1.\n\nReturns\n\nA Kaczmarz object.\n\ninfo: Info\nThe alpha parameter should be in (02)  for convergence to be guaranteed. This  condition is not enforced in the constructor. There are some instances where setting  alpha = 2 can lead to non-convergent cycles [10].\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.KaczmarzRecipe","page":"Solvers API","title":"RLinearAlgebra.KaczmarzRecipe","text":"KaczmarzRecipe{\n    T<:Number, \n    V<:AbstractVector,\n    M<:AbstractMatrix, \n    VV<:SubArray,\n    MV<:SubArray,\n    C<:CompressorRecipe, \n    L<:LoggerRecipe,\n    E<:SolverErrorRecipe, \n    B<:SubSolverRecipe\n} <: SolverRecipe\n\nA mutable structure containing all information relevant to the Kaczmarz solver. It is     formed by calling the function complete_solver on Kaczmarz solver, which includes     all the user controlled parameters, and the linear system matrix A and constant      vector b.\n\nFields\n\ncompressor::CompressorRecipe, a technique for forming the compressed rowspace of the    linear system.\nlog::LoggerRecipe, a technique for logging the progress of the solver.\nerror::SolverErrorRecipe, a method for estimating the progress of the solver.\nsub_solver::SubSolverRecipe, a technique to perform the projection of the solution onto   the compressed rowspace.\nalpha::Float64, the over-relaxation parameter. It is multiplied by the update and can    affect convergence.\ncompressed_mat::AbstractMatrix, a matrix container for storing the compressed matrix.    Will be set to be the largest possible block size.\ncompressed_vec::AbstractVector, a vector container for storing the compressed constant   vector. Will be set to be the largest possible block size.\nsolution_vec::AbstractVector, a vector container for storing the solution to the linear   system.\nupdate_vec::AbstractVector, a vector container for storing the update to the linear    system.\nmat_view::SubArray, a container for storing a view of compressed matrix container.    Using views here allows for variable block sizes.\nvec_view::SubArray, a container for storing a view of the compressed vector container.   Using views here allows for variable block sizes.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#RLinearAlgebra.complete_solver","page":"Solvers API","title":"RLinearAlgebra.complete_solver","text":"complete_solver(solver::Solver, x::AbstractVector, A::AbstractMatrix, b::AbstractVector)\n\nA function that generates a SolverRecipe given the      arguments.\n\nArguments\n\nsolver::Solver, a user-specified solver method.\nx::AbstractVector, a vector for the proposed solution. \nA::AbstractMatrix, a coefficient matrix. \nb::AbstractVector, a constant vector. \n\nOutputs\n\nA SolverRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#RLinearAlgebra.rsolve!","page":"Solvers API","title":"RLinearAlgebra.rsolve!","text":"rsolve!(\n    solver::SolverRecipe, \n    x::AbstractVector, \n    A::AbstractMatrix, \n    b::AbstractVector\n)\n\nA function that solves a linear system given the arguments.\n\nArguments\n\nsolver::SolverRecipe, a fully initialized realization for a    solver method for a specific linear system.\nx::AbstractVector, a vector for the proposed solution. \nA::AbstractMatrix, a coefficient matrix. \nb::AbstractVector, a constant vector. \n\nOutputs\n\nReturns nothing. Updates the SolverRecipe and x in place.\n\n\n\n\n\nrsolve!(\n    solver::Solver, \n    x::AbstractVector, \n    A::AbstractMatrix, \n    b::AbstractVector\n)\n\nA function that solves a linear system given the arguments.\n\nArguments\n\nsolver::Solver, a user-specified solver method.\nx::AbstractVector, a vector for the proposed solution. \nA::AbstractMatrix, a coefficient matrix. \nb::AbstractVector, a constant vector. \n\nOutputs\n\nx::AbstractVector, a proposed solution to a linear system or least squares    problem.\nA SolverRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#RLinearAlgebra.colproj_update!","page":"Solvers API","title":"RLinearAlgebra.colproj_update!","text":"colproj_update!(solver::ColumnProjectionRecipe)\n\nA function that performs the column projection update when the compression dimension  is one.  If a = AS is the resulting compression of the transpose of the coefficient matrix, and r = b - Ax is the current residual, this function computes x_+ = x + alpha S frac a^top (b-Ax) Vert a Vert_2^2 and  r_+ = r_- - alpha a frac a^top rVert a Vert_2^2\n\nArguments\n\nsolver::ColumnProjectionRecipe, the solver information required for performing the update.\n\nOutputs\n\nreturns nothing\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#RLinearAlgebra.colproj_update_block!","page":"Solvers API","title":"RLinearAlgebra.colproj_update_block!","text":"colproj_update_block!(solver::ColumnProjectionRecipe)\n\nA function that performs the column projection update when the compression dimension  is greater than 1. If S is the compression matrix,   the compressed matrix is tilde A = A S, and the residual is r = b - A x,  this function computes  v =  (tilde A^top tilde A)^dagger tilde A^top r and stores it in solver.update_vec; x_+ = x + alpha S v and stores it in solver.solution_vec; and r_+ = r - alpha tilde A v and stores it in solver.residual_vec.\n\nArguments\n\nsolver::ColumnProjectionRecipe, the solver information required for performing the update.\n\nOutputs\n\nreturns nothing\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#RLinearAlgebra.kaczmarz_update!","page":"Solvers API","title":"RLinearAlgebra.kaczmarz_update!","text":"kaczmarz_update!(solver::KaczmarzRecipe)\n\nA function that performs the Kaczmarz update when the compression dimension is one.      If a is the resulting compression of the coefficient matrix,      and c is the resulting compression of the constant vector,      then we perform the update: x = x - alpha (a^top x -c)  a_2^2. \n\nArguments\n\nsolver::KaczmarzRecipe, the solver information required for performing the update.\n\nOutputs\n\nreturns nothing\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#RLinearAlgebra.kaczmarz_update_block!","page":"Solvers API","title":"RLinearAlgebra.kaczmarz_update_block!","text":"kaczmarz_update_block!(solver::KaczmarzRecipe)\n\nA function that performs the kaczmarz update when the compression dim is greater than 1.       In the block case where the compressed matrix tilde A, and the compressed      contant vector tilde b, we perform the updated:      x = x - alpha tilde A^top (tilde A tilde A^top)^dagger     (tilde Ax-tilde b).\n\nArguments\n\nsolver::KaczmarzRecipe, the solver information required for performing the update.\n\nOutputs\n\nreturns nothing\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#RLinearAlgebra.dotu","page":"Solvers API","title":"RLinearAlgebra.dotu","text":"dotu(a::AbstractArray, b::AbstractArray)\n\nA function that computes the non conjugate dot product between two vectors. It is equivalent     to calling dot(conj(a), b).\n\nArguments\n\na::AbstractArray, a vector being dot producted (is labeled as a array to allow for    views).\nb::AbstractArray, a vector being dot producted (is labeled as a array to allow for    views).\n\nReturns\n\nA scalar that is the non-conjugated dot product between two vectors.\n\n\n\n\n\n","category":"function"},{"location":"manual/compression/#Compressing-a-Matrix/Vector","page":"Compression","title":"Compressing a Matrix/Vector","text":"Most Randomized Linear Algebra routines start by forming low-dimensional representation of  a matrix/vector. These representations are typically formed by multiplying a  random matrix with a large matrix/vector.  For instance, if we have x in mathbbR^10000 we can apply a matrix,  S in mathbbR^20 times 10000 made up of  independent and identically distributed textbfNormal(0 1sqrt20) to obtain y = Sx in mathbbR^20 where (1-epsilon)x leq y leq (1+epsilon) x with high probability. \n\nOf course, many other techniques beyond a Gaussian matrix can be used to generate  S and they vary both in terms of their approximation accuracy and computational  efficiency. In papers, Randomized Linear Algebraists often refer to techniques for generating S as either sampling (random subset of identity) or sketching  (general random matrix) techniques. For simplicity RLinearAlgebra.jl refers to both types  of techniques under the general family of Compressors. The choice of the terminology  Compressors also allows us to incorporate deterministic approaches to compressing  matrices/vectors. \n\nIn RLinearAlgebra.jl, using a compression technique requires two main steps. The first, uses the complete_compressor function to generate a CompressorRecipe. The second  step uses the mul! or * functions to apply your CompressorRecipe to your matrix/ vector object. If you ever want to form a new realization of your compressor, you can  use the update_compressor! function to update the random entries in your  CompressorRecipe. ","category":"section"},{"location":"manual/compression/#Using-complete_compressor","page":"Compression","title":"Using complete_compressor","text":"In its simplest form, complete_compressor has two arguments, the first is compressor, where you specify the compressor technique that you wish to use. All compressors have two fields that the user can specify; although some have some additional technique   specific fields (see Compressors API for more details). The first field  is compression_dim, where you specify the dimension that your CompressorRecipe will map  a matrix/vector into after being applied to the matrix/vector. The second field is  Cardinality, which can either be Left() or Right(). Cardinality allows you to  specify how you intend to multiply your compressor to a matrix/vector. In the matrix case,  if S is your CompressorRecipe and A is your matrix, a Left() cardinality  corresponds to multiplying SA and a Right() corresponds to multiplying AS. Once  you have specified these two fields in your Compressor object, the second input in to the  complete_compressor function will be the matrix/vector you wish to compress. ","category":"section"},{"location":"manual/compression/#Multiplying-your-CompressorRecipe","page":"Compression","title":"Multiplying your CompressorRecipe","text":"Once you have your CompressorRecipe you can multiply it to any matrix/vector  just as you would any matrix object, using either the mul! or * functions. You can also  take transposes of the CompressorRecipe just as you would any other matrix object.  Just like in LinearAlgebra, the mul! function should be used when you have preallocated  an output array and the * function should be used when you have not. \n\nnote: Effect of Cardinality on Multiplication\nProvided the dimensions align you can provide a compressor to the left or  right of a matrix or vector regardless of the Cardinality. However, if the  direction applied does not align with the Cardinality, this could be a slower  operation.","category":"section"},{"location":"manual/compression/#Updating-update_compressor!","page":"Compression","title":"Updating update_compressor!","text":"Because most compression techniques are randomized, it is likely that once you have a  realization of CompressorRecipe that you would want another realization of that same  recipe. This can be done using the update_compressor! function. This function in  its simplest form has only one argument although for some compressors it could have more arguments (see Compressors API for more details). The one argument is the  CompressorRecipe.","category":"section"},{"location":"manual/compression/#Compressing-a-Matrix-Example","page":"Compression","title":"Compressing a Matrix Example","text":"Knowing that compressors allow us to reduce one of the dimensions of a matrix, the next  important question is how do we do this in RLinearAlgebra.jl? In the following example  we show how to do exactly this using a Gaussian compressor. In this  example we will generate a GaussianRecipe, S, with compression_dim 10 and  cardinality Left(), then we will apply S and its transpose, S', to a matrix, A,  with a 100 rows and 100 columns using *.  Then we will generate a new realization of the recipe using  update_compressor! and use the mul! to apply this new compressor to A from  the left.\n\nusing RLinearAlgebra\nusing LinearAlgebra\n\nA = rand(100, 100)\n\n# Generate the CompressorRecipe with compression_dim 10 and cardinality Left()\nS = complete_compressor(\n    Gaussian(\n        compression_dim = 10,\n        cardinality = Left()\n    ),\n    A\n)\n\n# Multiply this compressor and its transpose to the left and right of A, respectively\nC = S * A * S'\n\n# Generate a new realization of S\nupdate_compressor!(S)\n\n# use mul! to multiply S from the left\n# the output matrix will have the number of rows in S and the number of columns in A\nC = zeros(size(S, 1), size(A, 2))\n\nmul!(C, S, A)","category":"section"},{"location":"manual/compression/#Sampling-Compressors-and-Distributions","page":"Compression","title":"Sampling Compressors and Distributions","text":"A special sub-type of compressors are known as Sampling compressors. These compressors are unique in that they compress the matrix by selecting rows or columns according to a  specific distribution. For example, we could compress a matrix by sampling 10 rows uniformly at random in what is known unsurprisingly as a uniform sampling approach. RLinearAlgebra.jl allows you to use the Sampling techniques with a wide range of distributions (see  Distributions for more details). You can specify the distribution you want to use with the distribution argument in the sampling structure. As an example, if we want to  perform uniform sampling from a matrix we can form our SamplingRecipe by writing:\n\nusing RLinearAlgebra\nA = rand(100, 100)\n\n# Generate Compression recipe using uniform sampling distribution\nS = complete_compressor(\n    Sampling(\n        compression_dim = 10,\n        cardinality = Left(),\n        distribution = Uniform()\n    ),\n    A\n)","category":"section"},{"location":"manual/compression/#Summary-of-Compressors","page":"Compression","title":"Summary of Compressors","text":"We now know that anytime we want to reduce one of the dimensions of a matrix or vector, we need to form a CompressorRecipe. To form the CompressorRecipe, we need to call complete_compressor with a Compressor data structure, which specifies the technique we want to use to compress a matrix/vector, and a matrix/vector that we wish to compress. Once we have this recipe, we can generate a new realization of it by calling  update_compressor! and can apply it to a matrix or vector using mul! or *. For more information on specific compressors see Compressors API.","category":"section"},{"location":"tutorials/compressors/compressor_example/#Multiplying-by-a-Compressor","page":"Multiplying by a Compressor","title":"Multiplying by a Compressor","text":"Let A be a matrix that we wish to compress for some subsequent calculation (e.g., approximating the column space or solving a least squares problem). \n\nA = randn(1000, 500)\n\nWe can generate any number of compressors (see Compressors API). We can then multiply A from the left or right by the compressor.  We provide three examples below:\n\nThe SparseSign compressor [5, Section 9.2].\nThe Gaussian compressor.\nA Uniform Sampling of the columns of A.\n\nusing RLinearAlgebra\n\nI1 = SparseSign(\n    cardinality=Left(), #Apply the compressor to the rows of A               \n    compression_dim=20, #Reduce the number of rows of A to 20\n    nnz=8,                      \n    type=Float64                  \n)\n\nI2 = Gaussian(\n    cardinality=Right(), #Apply the compressor to the columns of A\n    compression_dim=10,  #Reduce the number of columns of A to 10\n    type=Float64\n)\n\nI3 = Sampling(\n    cardinality=Right(), #Apply the compressor to the columns of A\n    compression_dim=15,  #Reduce the number of columns of A to 15\n    distribution=Uniform()\n)\n\nThe previous code block specifies the ingredients for constructing the three  compressors. The next code block constructs the compressors using  complete_compressor.\n\nC1 = complete_compressor(I1, A)\nC2 = complete_compressor(I2, A)\nC3 = complete_compressor(I3, A)\n\nWe can now apply the compressors to A. The first compressor reduces the  number of rows of A from 1000 to 20.\n\nCA1 = C1 * A\nsize(CA1)\n\nThe second compressor reduces the number of columns of A from 500 to 10.\n\nCA2 = A * C2\nsize(CA2)\n\nThe final compressor reduces the number of columns of A from 500 to 15.\n\nCA3 = A * C3\nsize(CA3)","category":"section"},{"location":"tutorials/least_squares/least_squares/#Solving-a-Least-Squares-Problem","page":"Solving a Least Squares Problem","title":"Solving a Least Squares Problem","text":"This guide demonstrates how to use RLinearAlgebra.jl package to approximately solve a linear least squares problem,\n\nmin_x Ax - b_2^2\n\nFirst, define A and b.\n\nnum_rows, num_cols = 1000, 50\nA = randn(Float64, num_rows, num_cols)\nb = A*randn(Float64, num_cols) + 0.1*randn(Float64, num_rows)\n\nRLinearAlgebra.jl can find an approximate least-squares solution using the generalized ColumnProjection method [6].\n\nusing RLinearAlgebra\nsolver = ColumnProjection(log = BasicLogger(max_it = 300))\nsolution = zeros(Float64, num_cols) # Initial guess of zeros\nrsolve!(solver, solution, A, b)\n\nrsolve! finds the least-squares solution and stores it in the solution vector.","category":"section"},{"location":"api/approximator_errors/#ApproximatorErrors","page":"ApproximatorErrors API","title":"ApproximatorErrors","text":"Pages = [\"approximator_errors.md\"]","category":"section"},{"location":"api/approximator_errors/#Abstract-Types","page":"ApproximatorErrors API","title":"Abstract Types","text":"","category":"section"},{"location":"api/approximator_errors/#ApproximatorError-Structures","page":"ApproximatorErrors API","title":"ApproximatorError Structures","text":"","category":"section"},{"location":"api/approximator_errors/#Exported-Functions","page":"ApproximatorErrors API","title":"Exported Functions","text":"","category":"section"},{"location":"api/approximator_errors/#RLinearAlgebra.ApproximatorError","page":"ApproximatorErrors API","title":"RLinearAlgebra.ApproximatorError","text":"ApproximatorError\n\nAn abstract supertype for structures containing user-controlled parameters corresponding to methods that evaluate the quality of a low-rank approximation of a matrix A.\n\n\n\n\n\n","category":"type"},{"location":"api/approximator_errors/#RLinearAlgebra.ApproximatorErrorRecipe","page":"ApproximatorErrors API","title":"RLinearAlgebra.ApproximatorErrorRecipe","text":"ApproximatorErrorRecipe\n\nAn abstract supertype for structures containing user-controlled parameters, matrix dependent parameters and preallocated memory corresponding to methods that evaluate the quality of a low-rank approximation of a matrix A.\n\n\n\n\n\n","category":"type"},{"location":"api/approximator_errors/#RLinearAlgebra.complete_approximator_error","page":"ApproximatorErrors API","title":"RLinearAlgebra.complete_approximator_error","text":"complete_approximator_error(\n    error::ApproximatorError, \n    approximator::ApproximatorRecipe, \n    A::AbstractMatrix\n)\n\nA function that generates an ApproximatorErrorRecipe     given the arguments.\n\nArguments\n\nerror::ApproximatorError, a data structure containing   the user-defined parameters associated with a particular low-rank approximation error   method.\napproximator::ApproximatorRecipe, a fully initialized   realization for a low rank approximation method for a particular matrix.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nAn ApproximatorErrorRecipe object.\n\n\n\n\n\n","category":"function"},{"location":"api/approximator_errors/#RLinearAlgebra.compute_approximator_error","page":"ApproximatorErrors API","title":"RLinearAlgebra.compute_approximator_error","text":"compute_approximator_error(\n    error::ApproximatorError, \n    approximator::ApproximatorRecipe, \n    A::AbstractMatrix\n)\n\nA function that computes the approximation error of an     ApproximatorRecipe for a matrix A.\n\nArguments\n\nerror::ApproximatorError, a data structure containing   the user-defined parameters associated with a particular low-rank approximation error   method.\napproximator::ApproximatorRecipe, a fully initialized   realization for a low rank approximation method for a particular matrix.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nReturns the error::Float64 \n\n\n\n\n\n","category":"function"},{"location":"api/approximator_errors/#RLinearAlgebra.compute_approximator_error!","page":"ApproximatorErrors API","title":"RLinearAlgebra.compute_approximator_error!","text":"compute_approximator_error!(\n    error::ApproximatorErrorRecipe, \n    approximator::ApproximatorRecipe, \n    A::AbstractMatrix\n)\n\nA function that computes the approximation error of an     ApproximatorRecipe for a matrix A.\n\nArguments\n\nerror::ApproximatorErrorRecipe, a fully initialized   realization for a low rank approximation error method for a particular matrix.\napproximator::ApproximatorRecipe, a fully initialized   realization for a low rank approximation method for a particular matrix.\nA::AbstractMatrix, a target matrix for approximation. \n\nOutputs\n\nReturns the error::Float64 \n\n\n\n\n\n","category":"function"},{"location":"manual/linear_systems/#Solving-Linear-Systems","page":"Linear Systems","title":"Solving Linear Systems","text":"Given a linear system consisting of a matrix A in mathbbR^m times n and constant vector b in mathbbR^m in the column space of A, we aim to  find x^* such that Ax^* = b.\n\nRLinearAlgebra allows you to find an approximation to a solution of the linear  system by calling the function rsolve!(solver, x, A, b),  where A is the coefficient matrix,  b is the constant vector,  and x is the initialization of the solution vector that will be replaced with solution produced by the solver.  The solver variable of type  Solver allows you to specify the algorithmic parameters specific to the solver  you wish to use to approximate a solution to the system. ","category":"section"},{"location":"manual/linear_systems/#Generalized-Kaczmarz-Method","page":"Linear Systems","title":"Generalized Kaczmarz Method","text":"Kaczmarz is one randomized approach for solving consistent linear systems with a nice  geometric interpretation. We can understand this geometric interpretation by first  recognizing that when a linear system has solution, x^*,   Ai  x^* = bi for every row of the linear system. Geometrically this means that x^* lies at the intersection of all row hyperplanes. Kaczmarz is able to converge to  this solution by projecting orthogonally from one hyperplane to the next.  Performing such  projects ensures that every update gets closer to the solution as can be seen in the  following figure.\n\n<img src=\"../images/kaczmarz.svg\" width =400 height = 300/> \n\nIn the following example, we run a Kaczmarz solver for 30 iterations.  To do this appropriately, we set the max_it field in the BasicLogger structure to be the  log field in the Kaczmarz solver.\n\nusing RLinearAlgebra\nusing LinearAlgebra\n\n# Generate the linear system\nA = rand(10, 10);\nx_sol = rand(10);\nb = A * x_sol;\n\n# create initalization for solution\nx = zeros(10);\n\n# Create the Kaczmarz Solver\nsolver = Kaczmarz(\n    log = BasicLogger(max_it = 30)\n);\n\n# solve the system\nrsolve!(solver, x, A, b)\n\n# Check error of solution \nnorm(x - x_sol)\n\nOften for Kaczmarz, we can improve the rate of convergence by projecting onto blocks of rows. In RLinearAlgebra we can do this by changing the compression_dim of the  compressor.  Below, we set the compression_dim = 5. We also may wish to  stop when the residual falls below 1e-1, which we do by specifying the threshold field in the Logger structure. After setting up these systems, we run our solver and plot the history of the FullResidual by plotting the hist field of log field of the returned  SolverRecipe.\n\nusing RLinearAlgebra\nusing LinearAlgebra\nusing Plots\n\n# Generate the linear system\nA = rand(10, 10);\nx_sol = rand(10);\nb = A * x_sol;\n\n# create initalization for solution\nx = zeros(10);\n\n# Create the Kaczmarz Solver\nsolver = Kaczmarz(\n    log = BasicLogger(\n        max_it = 100,\n        threshold = 1e-1\n         \n    ),\n    compressor = SparseSign(compression_dim = 5)\n);\n\n# solve the system\nx, kaczmarz_recipe = rsolve!(solver, x, A, b)\n\n# Check error of solution \nnorm(x - x_sol)\n\n# Plot the residual history\nplot(\n    kaczmarz_recipe.log.hist[kaczmarz_recipe.log.hist .> 0.0], \n    yscale = :log10, \n    xlab = \"Iteration\", \n    ylab = \"Norm of Residual\"\n)","category":"section"},{"location":"manual/linear_systems/#Solver-Concepts","page":"Linear Systems","title":"Solver Concepts","text":"Solvers tend to have the following fields.\n\nCompressor specifies how we will compress the system.\nSubSolver allows you to specify how to solve the compressed system.\nErrorMethod allows you to specify the technique that you wish to use to   determine a solver's progress.\nLogger performs two key tasks: (1) it stores the information from   an error method in a hist field and (2) it determines whether an inputted stopping   criterion is satisfied.\n\nSee the Solvers API for more details.","category":"section"},{"location":"#RLinearAlgebra","page":"Home","title":"RLinearAlgebra","text":"RLinearAlgebra is a Julia library for the  development and application of randomized algorithms to the problems of forming low rank  approximations to matrices and finding the solution of linear systems and least squares  problems.  Because of the large diversity of randomized techniques, rather than offering isolated  routine implementations of algorithms, this library implements a series of extendable data  structures and methods which allow code reuse.","category":"section"},{"location":"#Documentation-structure","page":"Home","title":"Documentation structure","text":"This documentation serves both as a manual to the library and as an introduction to  randomized linear approximation techniques and randomized linear algebra solvers.  We divide it in four parts:\n\nTutorial: examples of how to solve linear systems and least squares problems with   RLinearAlgebra and how to extend the library.\nManual: here we offer an introduction to solving linear systems with randomized linear    algebra techniques, compressing a matrix, and forming a low-rank approximation of a matrix.    We introduce theoretical foundations and we provide code examples with RLinearAlgebra.\nAPI: a detailed description of all the data structures and methods of the library.\nDevelopment: detailed instructions on how to contribute to the library.","category":"section"},{"location":"#Acknowledgements","page":"Home","title":"Acknowledgements","text":"This work is supported by the National Science Foundation Office of Advanced  Cyberinfrastructure under awards  2309445 and  2309446. This material is based upon work supported by the U.S. Department of Energy, Office of  Science, under contract number DE-AC02-06CH11357.","category":"section"},{"location":"api/contents/#Randomized-Linear-Solver-Reference","page":"Randomized Linear Solver Reference","title":"Randomized Linear Solver Reference","text":"Pages=[\n  \"approximators.md\",  \n  \"approximator_errors.md\",\n  \"compressors.md\",\n  \"solvers.md\",\n  \"solver_error.md\",\n  \"sub_solvers.md\",\n  \"loggers.md\"]","category":"section"},{"location":"tutorials/consistent_system/consistent_system/#Solving-a-Consistent-Linear-System","page":"Solving a Consistent Linear System","title":"Solving a Consistent Linear System","text":"This guide demonstrates how to use RLinearAlgebra.jl package to solve a  consistent linear system. That is, how to approximately find x that satisfies\n\nAx = b\n\nwhere A is a matrix; and b is a vector in the column space of A.\n\nDefine A and define b to be in the column space of A.\n\nnum_rows, num_cols = 100, 5\nA = randn(Float64, num_rows, num_cols)\nb = A*randn(Float64, num_cols)\n\nRLinearAlgebra.jl can find an approximate solution using the generalized  Kaczmarz method [6].\n\nusing RLinearAlgebra\nsolver = Kaczmarz(log = BasicLogger(max_it = 300))\nsolution = zeros(Float64, num_cols) # Initial guess of zeros\nrsolve!(solver, solution, A, b)\n\nrsolve! updates solution with the approximate solution.","category":"section"}]
}
